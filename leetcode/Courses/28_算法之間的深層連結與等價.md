# 算法之間的深層連結與等價 — 看見 LeetCode 背後的 Matrix

> **定位**：本檔案揭示看似不同的演算法之間的深層結構等價性。
> 當你理解這些連結，你不再是記住 20 種算法的人 — 你是理解「一種思想、多種面貌」的人。
> **適用對象**：已刷 80+ 題，想突破瓶頸、建立統一世界觀的人
> **語言**：繁體中文解說 + English technical terms
> **前置要求**：熟悉 01-17 基礎教學、18-20 情境解題地圖
> **核心主張**：所有演算法都在做同一件事。差別只在搜尋空間的形狀和你遍歷它的策略。

---

## 目錄

| 章 | 主題 | 核心洞察 |
|----|------|---------|
| 1 | 所有搜尋其實是同一件事 | 算法 = 搜尋策略 × 搜尋空間 |
| 2 | BFS 和 DP 的等價性 | 最短路徑 ≡ 最小步數 DP |
| 3 | DFS 和 Stack 的等價性 | 遞迴 = 隱式 Stack |
| 4 | Backtracking 就是 DFS | 回溯 = DFS + undo |
| 5 | Greedy 是 DP 的特殊情況 | 局部最優恰好 = 全域最優時 |
| 6 | Binary Search on Answer | 猜答案 + Greedy 驗證 |
| 7 | Union-Find 和 DFS 的等價性 | 連通性的兩種語言 |
| 8 | Monotonic Stack 和 DP 的關係 | 邊界展開 = 狀態轉移 |
| 9 | Prefix Sum 的 transformation | 子陣列問題 → Two Sum |
| 10 | 同一題的多種解法 | 五道經典題 × 3+ 種解法 |
| 11 | 圖論統一所有搜尋問題 | 終極抽象：一切皆是圖 |

---

## 第一章：所有搜尋其實是同一件事

### 核心洞察

> **每一個演算法，本質上都在做同一件事：在某個搜尋空間 (search space) 中，用某種策略 (strategy) 尋找最優解或可行解。**

差別不在「算法不同」，而在：
1. **搜尋空間的形狀** — 是線性？樹狀？圖狀？指數級？
2. **搜尋策略** — 全部走？砍半？貪心跳？記住走過的路？

### 統一視角表

| 算法 | 搜尋空間 | 搜尋策略 | 典型時間 | 本質一句話 |
|------|---------|---------|---------|-----------|
| Brute Force | 所有可能 | 全部嘗試 | O(n²) or worse | 不放過任何角落 |
| Binary Search | 有序空間 | 每次砍半 | O(log n) | 利用單調性排除一半 |
| Two Pointers | 有序空間 | 兩端夾擊 | O(n) | 利用排序從兩端逼近 |
| BFS | 圖/狀態空間 | 層層擴展 | O(V+E) | 最近的先探索 |
| DFS | 圖/狀態空間 | 一路到底 | O(V+E) | 深入再回頭 |
| DP | 子問題空間 | 記住已解的 | varies | 不重複計算同一子問題 |
| Greedy | 決策空間 | 局部最優 | O(n) usually | 每步選眼前最好的 |
| Backtracking | 排列/組合空間 | 試錯回退 | O(2^n) or O(n!) | 走不通就退回來 |

### 選擇算法 = 選擇搜尋策略

```
問自己三個問題：

1. 搜尋空間有多大？
   - 小 (n ≤ 20)     → Brute Force / Backtracking 可以硬搜
   - 中 (n ≤ 10^4)   → O(n²) 的 DP / Two Pointers 能過
   - 大 (n ≤ 10^6)   → 需要 O(n) 或 O(n log n) 的策略

2. 搜尋空間有什麼結構？
   - 有序的         → Binary Search / Two Pointers
   - 有重疊子問題    → DP
   - 是圖/狀態轉移   → BFS / DFS
   - 有 greedy choice property → Greedy

3. 要找什麼？
   - 最短路徑/最少步數 → BFS (unweighted) / Dijkstra (weighted)
   - 所有可能        → Backtracking / DFS
   - 最優值          → DP / Greedy
   - 是否可達        → DFS / BFS / Union-Find
```

### 一個例子看懂「同一問題，不同搜尋策略」

**問題：在 sorted array 中找 target**

```
策略 1 - Brute Force：逐個掃描 → O(n)
   搜尋空間：[0, 1, 2, ..., n-1]
   策略：從頭到尾看一遍

策略 2 - Binary Search：每次砍半 → O(log n)
   搜尋空間：同上，但利用「有序」這個結構
   策略：比較 mid，砍掉不可能的那一半

策略 3 - Hash Table：建表後 O(1) 查 → 建表 O(n)，查詢 O(1)
   搜尋空間：用 hash function 映射到 bucket
   策略：把「搜尋」轉換為「直接存取」
```

> **重點**：問題沒變，資料沒變。變的是你「怎麼看」搜尋空間。

---

## 第二章：BFS 和 DP 的等價性

### 令人震驚的事實

> **很多 BFS 問題可以用 DP 解，很多 DP 問題可以用 BFS 解。**
> 因為 BFS 的「層數」就是 DP 的「最小步數」。

### 等價關係圖

```
BFS                              DP
────────────                     ────────────
起點 = 初始狀態                    dp[start] = base case
每一層 = 一步操作                  dp[i] = min(dp[prev] + 1)
visited 避免重複                   dp table 記錄已算
到達終點的層數 = 答案               dp[target] = 答案
```

### Case Study 1: Coin Change (LC 322)

**問題**：用面額為 coins 的硬幣，湊出 amount，最少要幾枚？

**BFS 視角 — 最短路徑問題**

```
把這想成一張圖：
- 節點：0, 1, 2, ..., amount（代表目前湊到多少錢）
- 邊：從節點 v 到節點 v + coin（每種硬幣是一種「走法」）
- 起點：0
- 終點：amount
- 求：從 0 到 amount 的最短路徑（最少幾步 = 最少幾枚硬幣）

BFS 逐層展開：
Layer 0: {0}
Layer 1: {0+1, 0+2, 0+5} = {1, 2, 5}       ← 用了 1 枚硬幣能到的地方
Layer 2: {2, 3, 6, 3, 4, 7, 6, 7, 10}       ← 用了 2 枚硬幣能到的地方
...
第一次到達 amount 的那一層 = 答案
```

**DP 視角 — 最優子結構問題**

```python
dp[i] = min(dp[i - coin] + 1 for coin in coins if i - coin >= 0)
# dp[i] = 湊出 i 元最少需要幾枚硬幣
# Base case: dp[0] = 0（湊出 0 元需要 0 枚）
```

**為什麼等價？**

```
BFS 的 Layer k = 所有「用 k 枚硬幣能到達的金額」
DP 的 dp[i] = k 表示「金額 i 最早在第 k 層被 BFS 到達」

兩者計算的是完全相同的東西！
BFS 從起點往外擴展 → 找到終點
DP 從小問題往大問題推 → 推到目標

差別只在遍歷順序：
- BFS: 按層數（步數）從小到大
- DP: 按金額從小到大
```

### Case Study 2: Jump Game II (LC 45)

**問題**：從 index 0 跳到最後，最少跳幾次？

**BFS 視角**

```
Layer 0: {0}                          ← 起點
Layer 1: {1, 2, ..., nums[0]}        ← 跳 1 次能到的所有位置
Layer 2: {從 Layer 1 的所有位置再跳一次能到的位置}
...

每一層 = 跳一次能到的範圍
第一次覆蓋到 n-1 的那一層 = 答案
```

**Greedy 視角 (等價於 BFS 但更高效)**

```python
jumps = 0
current_end = 0    # 目前這一層的邊界
farthest = 0       # 這一層能到的最遠位置

for i in range(len(nums) - 1):
    farthest = max(farthest, i + nums[i])
    if i == current_end:       # 走到這一層的邊界了
        jumps += 1             # 必須再跳一次
        current_end = farthest # 下一層的邊界 = 目前最遠
```

**等價性解釋**

```
Greedy 的 current_end = BFS 每一層的右邊界
Greedy 的 farthest    = BFS 下一層的右邊界
Greedy 的 jumps       = BFS 的層數

Greedy 之所以能用，是因為：
在 BFS 的同一層內，到達順序不影響結果。
我們只關心「這一層最遠能到哪」，不關心「從哪個節點跳過去的」。
所以不需要真的維護 queue，只需要追蹤邊界。
```

### Case Study 3: Word Ladder (LC 127)

```
BFS: 每個 word 是節點，differ by 1 letter = 邊
     從 beginWord BFS 到 endWord → 最短轉換序列

這題很難用 DP 做，因為：
- 狀態空間不是線性的（是 implicit graph）
- 很難定義「子問題」的順序

→ BFS 和 DP 不是「永遠」等價，而是在狀態空間可線性化時等價。
```

### 何時等價？何時不等價？

```
等價的條件：
✓ 狀態空間可以用整數 index 或 tuple 表示
✓ 轉移只依賴「較小的」子問題（DAG 結構）
✓ 求的是最小步數/最少代價

BFS 更適合：
- 狀態空間是 implicit graph（不好用 index 編號）
- 轉移方向不規則

DP 更適合：
- 狀態空間是 1D/2D array
- 轉移有明確的方向（左→右，小→大）
- 需要更多的狀態資訊（不只是步數）
```

---

## 第三章：DFS 和 Stack 的等價性

### 本質：誰管理 call stack？

> **遞迴 DFS 和迭代 DFS 是 100% 等價的。差別只在：call stack 是系統幫你管，還是你自己管。**

```
遞迴 DFS:                         迭代 DFS:
─────────                          ─────────
def dfs(node):                     stack = [root]
    if not node: return             while stack:
    process(node)                       node = stack.pop()
    dfs(node.left)                      process(node)
    dfs(node.right)                     stack.append(node.right)  # right first!
                                        stack.append(node.left)   # so left pops first

系統 call stack                     你的顯式 stack
自動 push/pop frame                 手動 push/pop node
stack overflow 風險                  不會 overflow（除非記憶體用完）
寫起來簡潔                          寫起來囉嗦但可控
```

### Tree Traversal 的 Stack 等價

**Preorder (根→左→右)**

```python
# 遞迴版 — 系統 call stack
def preorder(root):
    if not root: return
    result.append(root.val)    # 先處理根
    preorder(root.left)
    preorder(root.right)

# 迭代版 — 顯式 stack
def preorder(root):
    stack, result = [root], []
    while stack:
        node = stack.pop()
        if node:
            result.append(node.val)
            stack.append(node.right)   # 先 push right
            stack.append(node.left)    # 再 push left（這樣 left 先 pop）
    return result
```

**Inorder (左→根→右) — 迭代版較複雜**

```python
# 迭代版的直覺：一路往左走到底，然後彈出、處理、轉向右
def inorder(root):
    stack, result = [], []
    curr = root
    while curr or stack:
        while curr:                 # 一路往左走到底
            stack.append(curr)
            curr = curr.left
        curr = stack.pop()          # 彈出（這是最左的未處理節點）
        result.append(curr.val)     # 處理它
        curr = curr.right           # 轉向右子樹
    return result

# 為什麼 inorder 複雜？
# 因為處理順序是「左→根→右」，根不是第一個被處理的。
# 你必須先走到最左邊，才能開始處理。
# Preorder 簡單是因為根第一個處理，pop 出來就處理。
```

### 為什麼要知道這個等價性？

```
面試場景 1: 面試官要求把遞迴改迭代 → 標準考題
面試場景 2: 遞迴深度爆掉 (tree 深度 10^5) → 必須改迭代避免 stack overflow
面試場景 3: BST Iterator (LC 173) → 顯式 stack 可「暫停/恢復」遍歷
```

---

## 第四章：Backtracking 就是 DFS

### 回溯法不是新算法

> **Backtracking = DFS on a decision tree + 在離開節點時 undo（撤銷）選擇。**

```
DFS 本身：
  遍歷每個節點 → 探索完一條路 → 回到分岔點 → 探索另一條路

Backtracking = DFS + 兩個額外操作：
  1. 在進入節點時：make a choice（做一個選擇）
  2. 在離開節點時：undo the choice（撤銷這個選擇）

這就是為什麼 backtracking 的模板永遠是：
  choose → explore → unchoose
```

### 統一模板

```python
def backtrack(path, choices):
    if is_solution(path):
        result.append(path[:])    # 找到一個解
        return

    for choice in choices:
        if is_valid(choice):      # 剪枝 (pruning)
            path.append(choice)   # choose（做選擇）
            backtrack(path, next_choices)  # explore（DFS 深入）
            path.pop()            # unchoose（撤銷選擇）← 這就是「回溯」
```

### 三大經典問題的 DFS Decision Tree

**Subsets (LC 78) — 每個元素 include 或 exclude**

```
                        []
                       /  \
                   [1]     []           ← 對 1 的決策：選 or 不選
                  /   \   /   \
              [1,2] [1] [2]   []       ← 對 2 的決策
              / \  / \ / \   / \
          [1,2,3]...              []   ← 對 3 的決策

DFS 這棵 decision tree → 所有 leaf = 所有 subset
每一層 = 一個元素的「選/不選」決策
```

**Permutations (LC 46) — 每步從剩餘元素中選一個**

```
                          []
                     /    |    \
                  [1]    [2]    [3]          ← 第一位放誰？
                 / \    / \    / \
             [1,2][1,3][2,1][2,3][3,1][3,2]  ← 第二位放誰？
              |    |    |    |    |    |
            [1,2,3]... (全排列)               ← 第三位只剩一個

DFS 這棵 decision tree，每個 leaf = 一個 permutation
```

**N-Queens (LC 51) — 每行放一個皇后**

```
Row 0: try column 0, 1, 2, 3
  Row 1: try valid columns (不同行、列、對角線)
    Row 2: try valid columns
      Row 3: try valid columns → 找到一個解 or 走不通 → 回溯

DFS + 剪枝（invalid column 直接跳過）= 高效回溯
```

### Backtracking vs Pure DFS 的微妙差異

```
Pure DFS (如 Graph Traversal):
  - visited 標記是「永久的」（一旦標記就不會取消）
  - 目的：遍歷所有可達節點
  - 一個節點只被探索一次

Backtracking:
  - 選擇是「臨時的」（離開時撤銷）
  - 目的：找出所有可能的路徑/組合
  - 同一個節點可能在不同路徑中被「經過」多次
```

---

## 第五章：Greedy 是 DP 的特殊情況

### DP vs Greedy 的本質差異

```
DP 的思路：
  在每個決策點，我考慮「所有可能的選擇」，
  對每個選擇都算出它的最優結果，
  然後選最好的那個。

  → dp[i] = best of (dp[prev] + cost_of_choice) for ALL choices

Greedy 的思路：
  在每個決策點，我只看「當下最好的選擇」，
  直接走那條路，不回頭。

  → result += locally_best_choice at each step
```

### Greedy 何時等於 DP？

> **當 locally optimal = globally optimal 時，Greedy 和 DP 給出相同答案。**
> 這就是 **Greedy Choice Property**。

### 具體案例對比

**Case 1: Activity Selection — Greedy = DP 的最優解**

```
問題：最多能參加幾個不重疊的活動？

DP 解法：
  dp[i] = max(dp[j] + 1) for all j where activity j ends before activity i starts
  時間：O(n²) 或 O(n log n) with binary search

Greedy 解法：
  按結束時間排序，每次選最早結束的活動
  時間：O(n log n)

為什麼 Greedy 有效？
  選最早結束的活動 → 留給後面的時間最多 → 不可能有更好的選擇
  數學證明：交換論證 (exchange argument) — 任何不選最早結束的方案，
  都可以被「換成」選最早結束的方案而不變差。
```

**Case 2: Jump Game (LC 55) — Greedy = DP 的最優解**

```
DP 解法：
  dp[i] = True if any dp[j] is True and j + nums[j] >= i
  時間：O(n²)

Greedy 解法：
  max_reach = 0
  for i in range(n):
      if i > max_reach: return False
      max_reach = max(max_reach, i + nums[i])
  return True
  時間：O(n)

為什麼 Greedy 有效？
  如果 position j 可達且 j + nums[j] >= i，那 i 也可達。
  我們只需追蹤「目前能到的最遠位置」。
  不需要記住每個位置是否可達。
```

**Case 3: 0/1 Knapsack — Greedy ≠ DP**

```
DP 解法：
  dp[i][w] = max(dp[i-1][w], dp[i-1][w-weight[i]] + value[i])
  考慮每個物品的「選」和「不選」

Greedy 嘗試（按 value/weight ratio 排序，選 ratio 最高的）：
  物品 A: weight=10, value=60 (ratio=6)
  物品 B: weight=20, value=100 (ratio=5)
  物品 C: weight=30, value=120 (ratio=4)
  背包容量 W=50

  Greedy: 選 A(10) + B(20) = weight 30, value 160，還剩 20 但 C 放不下 → 160
  DP:     選 B(20) + C(30) = weight 50, value 220 → 220 ✓

  Greedy 錯了！因為選了 ratio 最高的 A 之後，剩餘空間的組合不一定最好。
```

**Case 4: Coin Change — 取決於硬幣面額**

```
面額 = [1, 5, 10, 25] (美國硬幣)
  Greedy 有效！每次選最大面額 → 最少硬幣數

面額 = [1, 3, 4], amount = 6
  Greedy: 4 + 1 + 1 = 3 枚
  DP:     3 + 3     = 2 枚 ← 最優
  Greedy 錯了！

→ Greedy 對 Coin Change 有效的充要條件跟面額的數學性質有關，
  一般情況下必須用 DP。
```

### 判斷能否用 Greedy 的心法

```
問自己：
  「如果我現在做了局部最優的選擇，
   會不會在未來某個時刻後悔？」

如果答案是「絕對不會後悔」→ Greedy works
如果答案是「可能會後悔」  → 必須用 DP

更正式的判斷：
1. Greedy Choice Property: 局部最優選擇不會排除全域最優解
2. Optimal Substructure: 做完選擇後，剩下的子問題仍具最優子結構

兩者都滿足 → Greedy
只滿足 2   → DP (有最優子結構但沒有 greedy choice property)
```

---

## 第六章：Binary Search on Answer = 猜答案 + Greedy 驗證

### 這個 pattern 為什麼強大？

> **一大類「最小化最大值」或「最大化最小值」的問題，都可以用同一個框架解：**
> 1. 猜一個答案 mid
> 2. 用 O(n) 的 greedy/check function 驗證 mid 是否可行
> 3. 根據可行性做 binary search 調整

### 為什麼可以 Binary Search？

```
關鍵前提：答案具有單調性 (monotonicity)

例如：「船的容量至少要多大才能在 D 天內運完？」
  - 容量 = 1: 不行（太小）
  - 容量 = 2: 不行
  - ...
  - 容量 = 15: 剛好可以 ← 這是答案
  - 容量 = 16: 可以（更寬裕）
  - 容量 = 17: 可以

可行性是單調的：[不行, 不行, ..., 不行, 可以, 可以, ..., 可以]
                                          ↑ 找這個分界點

這就是 Binary Search 的標準場景！
```

### 統一模板

```python
def binary_search_on_answer(nums, constraint):
    lo, hi = min_possible_answer, max_possible_answer

    while lo < hi:
        mid = (lo + hi) // 2
        if check(mid, nums, constraint):   # mid 可行嗎？
            hi = mid          # 可行，試試更小的（找最小可行解）
        else:
            lo = mid + 1      # 不可行，答案必須更大

    return lo

def check(mid, nums, constraint):
    # O(n) greedy: 假設答案是 mid，能不能滿足 constraint？
    ...
```

### 三道經典題的深入拆解

**LC 875 Koko Eating Bananas**

```
問題：Koko 每小時吃 k 根香蕉，有 h 小時，能吃完所有堆嗎？最小的 k？

Binary Search:
  lo = 1, hi = max(piles)
  猜 mid = 每小時吃 mid 根

Check function:
  def can_finish(speed, piles, h):
      hours_needed = sum(ceil(pile / speed) for pile in piles)
      return hours_needed <= h

  這是一個 O(n) 的 greedy check！

  speed=3, piles=[3,6,7,11]:
    pile 3: ceil(3/3)=1 小時
    pile 6: ceil(6/3)=2 小時
    pile 7: ceil(7/3)=3 小時
    pile 11: ceil(11/3)=4 小時
    total = 10 小時

Binary Search 在答案空間 [1, max(piles)] 上找最小可行的 speed。
```

**LC 410 Split Array Largest Sum**

```
問題：把陣列分成 m 個子陣列，讓「最大子陣列和」最小。

Binary Search:
  lo = max(nums)       ← 最小可能答案（至少要能放最大的那個元素）
  hi = sum(nums)       ← 最大可能答案（全部放一組）

Check function:
  def can_split(max_sum, nums, m):
      count = 1           # 目前用了幾組
      current_sum = 0
      for num in nums:
          if current_sum + num > max_sum:
              count += 1  # 開新的一組
              current_sum = num
          else:
              current_sum += num
      return count <= m   # 組數不超過 m 就可行

  這是一個 O(n) 的 greedy：從左到右盡量塞，塞不下就開新組。

  nums=[7,2,5,10,8], m=2, 猜 max_sum=18:
    組1: 7+2+5=14 (加10會變24>18，所以開新組)
    組2: 10+8=18
    count=2 ≤ m=2 → 可行！ → 試試更小的 max_sum
```

**LC 1011 Capacity To Ship Packages Within D Days**

```
問題：最小船容量，使得 D 天內能運完所有包裹？

Binary Search:
  lo = max(weights)    ← 至少要能裝最重的那個
  hi = sum(weights)    ← 一天全部裝完

Check function:
  def can_ship(capacity, weights, days):
      day_count = 1
      current_load = 0
      for w in weights:
          if current_load + w > capacity:
              day_count += 1
              current_load = w
          else:
              current_load += w
      return day_count <= days

注意到了嗎？check function 跟 LC 410 幾乎一模一樣！
因為本質上是同一個問題：
  410: 分成 m 組，最小化最大組和
  1011: 分成 D 組，最小化最大組和（組 = 天）
```

### 辨識信號

```
看到以下關鍵詞 → 想 Binary Search on Answer：
  - "minimize the maximum ..."
  - "maximize the minimum ..."
  - "at least / at most ... within ... constraint"
  - "what is the minimum capacity / speed / distance such that ..."
```

---

## 第七章：Union-Find 和 DFS 的等價性

### 連通性問題的兩種語言

> **「A 和 B 是否連通？」這個問題，DFS 和 Union-Find 都能回答。**
> 差別在於：一次性查詢 vs 動態查詢。

### Static Graph: DFS 就夠了

```python
# 從 A 出發 DFS，看能不能到達 B → graph reachability
# 找所有連通分量 → 對每個未訪問節點觸發 DFS，count += 1
```

### Dynamic Graph: Union-Find 更強

```python
# 邊一條一條加入，每次都要回答「A 和 B 連通嗎？」
# Union-Find: find(x) 找根，union(x,y) 合併集合
# 路徑壓縮 + 按 rank 合併 → 幾乎 O(1) per operation
```

### Number of Islands (LC 200) — 兩種解法對照

```
DFS: 遍歷 grid，遇到 '1' 就 DFS 標記整個島 → count += 1
UF:  遍歷 grid，遇到 '1' 就跟相鄰 '1' union → 數不同 root

靜態版本兩者效能差不多。
但動態版 (LC 305 Number of Islands II)，
每次加入一塊陸地就要回報島嶼數 → Union-Find 遠勝 DFS。
```

### 選擇指南

```
用 DFS/BFS:
  - 一次性遍歷整個圖
  - 需要路徑資訊（不只是連通性）
  - 圖是靜態的

用 Union-Find:
  - 邊動態加入
  - 頻繁查詢「x 和 y 連通嗎？」
  - 需要維護連通分量數量
  - 不需要路徑資訊，只要 yes/no
```

---

## 第八章：Monotonic Stack 和 DP 的關係

### 同一個問題的兩種思路

> **Monotonic Stack 計算的東西，往往等價於某種 DP 的邊界計算。**

### Case Study: Largest Rectangle in Histogram (LC 84)

**問題**：在高度陣列中找最大矩形面積。

**DP 思路：對每個 bar，算它能往左/右延伸多遠**

```python
# 預處理：left[i] = bar i 往左能延伸到的最左 index
# 預處理：right[i] = bar i 往右能延伸到的最右 index
# 面積 = heights[i] * (right[i] - left[i] + 1)

left = [0] * n
right = [0] * n

# 往左延伸
for i in range(n):
    j = i - 1
    while j >= 0 and heights[j] >= heights[i]:
        j = left[j] - 1   # 跳躍式延伸（類似 DP）
    left[i] = j + 1

# 往右延伸
for i in range(n-1, -1, -1):
    j = i + 1
    while j < n and heights[j] >= heights[i]:
        j = right[j] + 1
    right[i] = j - 1
```

**Monotonic Stack 思路：維護遞增 stack**

```python
stack = []  # 存 index，對應的 heights 嚴格遞增
max_area = 0

for i in range(n + 1):
    h = heights[i] if i < n else 0
    while stack and heights[stack[-1]] > h:
        height = heights[stack.pop()]
        width = i - stack[-1] - 1 if stack else i
        max_area = max(max_area, height * width)
    stack.append(i)
```

**兩者為什麼等價？**

```
Monotonic Stack 在 pop 的時候，隱含計算了：
  - 左邊界 = stack[-1]（stack 中前一個元素 = 左邊第一個更矮的 bar）
  - 右邊界 = i（當前觸發 pop 的元素 = 右邊第一個更矮的 bar）

這跟 DP 版本計算的 left[i] 和 right[i] 是完全相同的資訊！

差別：
  - DP 版: 先算所有 left 和 right，再算面積 → 兩趟
  - Stack 版: 邊走邊算 → 一趟，但同時隱含了 left 和 right 的計算
```

### Next Greater Element 的統一視角

```
Monotonic Stack 解決的核心問題：
  對每個元素，找它「左邊/右邊第一個比它大/小的元素」

這等價於 DP：
  right_greater[i] = first j > i where nums[j] > nums[i]

Stack 把這個 O(n²) 的暴力搜尋壓縮到 O(n)，
因為 stack 中保存了「還沒找到答案的元素」，
一旦新元素比 stack top 大，就一次解決掉所有比它小的等待者。
```

---

## 第九章：Prefix Sum 把子陣列問題變成兩點問題

### 核心 Transformation

> **Prefix Sum 是一種座標變換：把「區間和」問題變成「兩點差」問題。**

```
原始問題：sum(nums[i..j]) = ?

暴力：每次 O(n) 加總
Prefix Sum：O(1) 查詢

prefix[0] = 0
prefix[k] = nums[0] + nums[1] + ... + nums[k-1]

sum(nums[i..j]) = prefix[j+1] - prefix[i]

一次 O(n) 建表，之後每次 O(1) 查詢。
```

### 驚人連結：Subarray Sum = Two Sum

**LC 560 Subarray Sum Equals K**

```
問題：找所有和為 k 的連續子陣列數量

暴力 O(n²)：嘗試所有 (i, j) 組合

Prefix Sum + HashMap O(n)：

  sum(i..j) = k
  → prefix[j+1] - prefix[i] = k
  → prefix[i] = prefix[j+1] - k

  這就是 Two Sum！
  「找之前是否存在一個 prefix sum 等於 current_prefix - k」
  用 HashMap 記錄每個 prefix sum 出現的次數。
```

```python
def subarraySum(nums, k):
    count = 0
    prefix_sum = 0
    seen = {0: 1}          # prefix_sum = 0 出現 1 次（空前綴）

    for num in nums:
        prefix_sum += num
        target = prefix_sum - k      # 我需要找的 prefix sum
        count += seen.get(target, 0)  # 之前有幾個 prefix sum 等於 target？
        seen[prefix_sum] = seen.get(prefix_sum, 0) + 1

    return count

# 對照 Two Sum (LC 1):
# 找 nums[i] + nums[j] = target
# → nums[j] = target - nums[i]
# → HashMap 存已見過的數，查 complement 是否存在

# 完全相同的 pattern！
# Subarray Sum = K 就是在 prefix sum 陣列上做 Two Sum。
```

### Prefix Sum 家族

```
Prefix Sum 的變體都在做相同的 transformation：

1D Prefix Sum:  sum(i..j) = prefix[j+1] - prefix[i]
2D Prefix Sum:  sum of submatrix = inclusion-exclusion on 4 corners
Prefix XOR:     XOR(i..j) = prefix_xor[j+1] ^ prefix_xor[i]
Prefix Product:  product(i..j) = prefix_prod[j+1] / prefix_prod[i]

核心思想完全一樣：把「區間查詢」轉換成「端點運算」。
```

### 為什麼 Prefix Sum + HashMap 這麼常見？

```
因為它把兩個強力工具結合起來：
  Prefix Sum: 把子陣列問題 → 兩點問題
  HashMap: O(1) 查找

結果：O(n²) 暴力 → O(n) 優雅解

這個組合出現在：
  LC 560 Subarray Sum Equals K
  LC 525 Contiguous Array (0/1 → -1/+1 transformation + prefix sum)
  LC 974 Subarray Sums Divisible by K (prefix sum mod k)
  LC 930 Binary Subarrays With Sum
```

---

## 第十章：同一題的多種解法 — 理解每個解法為什麼對

> **這一章是本文精華。同一道題用不同算法解，然後理解它們為什麼殊途同歸。**

### Problem 1: Number of Islands (LC 200)

```
解法 A — DFS (Flood Fill):
  遍歷 grid，遇到 '1' 就 DFS 把整個島標記為 '0'（沉島），count += 1

解法 B — BFS:
  同上，只是用 queue 而非 recursion 來遍歷連通的 '1'

解法 C — Union-Find:
  遍歷 grid，遇到 '1' 就跟相鄰的 '1' 做 union，最後數不同的 root 數

深層連結：
  三者都在做同一件事 — 找連通分量 (connected components)
  DFS = depth-first 遍歷 | BFS = breadth-first 遍歷 | UF = incremental merging
```

---

### Problem 2: Coin Change (LC 322)

```
解法 A — DP Bottom-up:
  dp[i] = min(dp[i-coin] + 1)，從 dp[0]=0 往上填到 dp[amount]

解法 B — BFS:
  起點=0，每步 +coin，層層擴展，第一次到達 amount 的層數 = 答案

解法 C — DFS + Memoization (Top-down DP):
  dfs(amount) 往下遞迴到 dfs(0)，用 memo dict 避免重複計算

深層連結：
  三者遍歷的是同一個 DAG：
    節點 = 金額 0, 1, ..., amount
    邊 = 每種硬幣（從 v 到 v+coin）
  Bottom-up: 按拓撲序（金額由小到大）遍歷
  Top-down: 按遞迴需求遍歷（memo 避免重複）
  BFS: 按層數（硬幣數）遍歷 → 層數就是最少硬幣數
```

---

### Problem 3: Jump Game (LC 55)

```
解法 A — DP O(n²):
  dp[i] = True if any dp[j] is True and j + nums[j] >= i

解法 B — Greedy O(n):
  追蹤 max_reach = max(max_reach, i + nums[i])
  如果 i > max_reach → return False

解法 C — Backward Greedy O(n):
  goal = n-1，從右往左掃，if i + nums[i] >= goal: goal = i
  最後 return goal == 0

深層連結：
  Greedy 能取代 DP 的原因：可達性有「連續性」
  如果 max_reach >= i，那 0 到 i 之間所有位置都可達
  不需要逐個記錄 dp[i]，只要一個數字就夠

  Backward Greedy：把終點不斷前移
  如果存在路徑 0→...→n-1，必存在 0→...→goal'→n-1
  其中 goal' 是最近的能到達目標的中繼站
```

---

### Problem 4: Best Time to Buy and Sell Stock II (LC 122)

```
解法 A — DP (hold / not_hold states):
  hold = max(hold, not_hold - price)      # 繼續持有 or 今天買
  not_hold = max(not_hold, hold + price)  # 繼續空手 or 今天賣

解法 B — Greedy (collect all positive differences):
  profit += max(0, prices[i] - prices[i-1])  # 每個上漲都收割

解法 C — Peak-Valley:
  找到每個低谷買入、每個高峰賣出，profit += peak - valley

深層連結：
  Greedy 的數學基礎：
    peak - valley = (day2-day1) + (day3-day2) + ... + (peak - day_before_peak)
    一段上漲的總利潤 = 每天正漲幅的總和
    所以收集所有「正的日差」= 最優解

  三者角度不同但結果相同：
    DP: 狀態轉移嚴謹框架
    Greedy: 數學等式的巧妙應用
    Peak-Valley: 直覺上的「低買高賣」
```

---

### Problem 5: Word Break (LC 139)

```
解法 A — DP:
  dp[i] = s[0..i-1] 能不能被拆分
  dp[i] = any(dp[j] and s[j:i] in dict) for j in [0..i-1]

解法 B — BFS:
  節點 = string index，邊 = 字典中的 word
  從 index 0 出發，if s[start:end] in dict → 加入 queue
  到達 len(s) 就是 True

解法 C — Trie + DP:
  建 Trie，DP 時沿 Trie 走 → 不需嘗試所有 j，前綴不匹配直接 break

深層連結：
  三者都在 string index 構成的 DAG 上找路徑：
    節點 = index 0, 1, ..., n
    邊 = 字典裡的 word（從 j 到 j+len(word)）
    問題 = 是否存在從 0 到 n 的路徑

  DP: 按 index 順序遍歷
  BFS: 按步數遍歷
  Trie: 加速「哪些邊存在」的查詢
```

---

## 第十一章：圖論統一所有搜尋問題

### 終極洞察

> **幾乎所有搜尋和最佳化問題，都可以被建模為圖上的問題。
> 不同的「算法」只是在不同形狀的圖上用不同策略遍歷。**

### 一切皆是圖

```
┌─────────────────────────────────────────────────────────────────┐
│                     一切皆是圖                                    │
├──────────────────┬──────────────────────────────────────────────┤
│  原始問題          │  圖的解讀                                     │
├──────────────────┼──────────────────────────────────────────────┤
│  Array            │  implicit graph: index i → i+1              │
│                   │  (or i → i+nums[i] for jump problems)       │
├──────────────────┼──────────────────────────────────────────────┤
│  String transform │  implicit graph: word → word                │
│                   │  (differ by 1 letter = edge)                │
├──────────────────┼──────────────────────────────────────────────┤
│  State space      │  graph: state → state                       │
│                   │  (each valid transition = edge)             │
├──────────────────┼──────────────────────────────────────────────┤
│  DP table         │  DAG: cell → dependent cells                │
│                   │  (topological order = DP computation order) │
├──────────────────┼──────────────────────────────────────────────┤
│  Tree             │  special graph: connected, acyclic          │
│                   │  (root + parent-child = directed tree)      │
├──────────────────┼──────────────────────────────────────────────┤
│  Matrix/Grid      │  graph: cell (i,j) → adjacent cells        │
│                   │  (4-directional or 8-directional)           │
├──────────────────┼──────────────────────────────────────────────┤
│  Decisions        │  decision tree: each choice = branch        │
│                   │  (backtracking = DFS on this tree)          │
└──────────────────┴──────────────────────────────────────────────┘
```

### 問題類型 → 圖演算法的映射

```
「最少幾步從 A 到 B？」
  → unweighted graph → BFS（因為 BFS 找的就是最短路徑）
  → weighted graph   → Dijkstra / Bellman-Ford

「A 能不能到達 B？」
  → graph connectivity → DFS / BFS / Union-Find

「列出所有從 A 到 B 的路徑」
  → DFS with backtracking（收集所有路徑）

「從 A 到 B 的最低成本路徑」
  → weighted shortest path → Dijkstra
  → 如果是 DAG → 拓撲排序 + DP

「把所有節點分成最少的群組，使得同組內都連通」
  → connected components → DFS / BFS / Union-Find

「是否存在不衝突的安排方式」
  → graph coloring / bipartite check → BFS/DFS

「什麼順序處理才不會有依賴衝突」
  → topological sort → Kahn's algorithm (BFS) / DFS
```

### 具體例子：Jump Game 的圖論視角

```
nums = [2, 3, 1, 1, 4]

圖的建模：
  節點: 0, 1, 2, 3, 4
  邊:   0→1, 0→2 (nums[0]=2, 從 0 最多跳 2 步)
        1→2, 1→3, 1→4 (nums[1]=3)
        2→3 (nums[2]=1)
        3→4 (nums[3]=1)

  0 → 1 → 4  (2 jumps)
  0 → 2 → 3 → 4  (3 jumps)
  0 → 1 → 2 → 3 → 4  (4 jumps)
  0 → 1 → 3 → 4  (3 jumps)

  LC 55 (能不能到？) = 圖的 reachability → DFS/BFS/Greedy
  LC 45 (最少幾步？) = 最短路徑 → BFS/Greedy
```

### 具體例子：DP 就是 DAG 上的最短/最長路徑

```
Fibonacci: dp[i] = dp[i-1] + dp[i-2]

DAG 長這樣：
  dp[0] → dp[2] → dp[4] → ...
  dp[1] → dp[2] → dp[3] → dp[4] → ...
            ↓       ↓
           dp[3]   dp[5]

每個 dp[i] 的「入邊」= 它依賴的子問題
拓撲序 = 0, 1, 2, 3, 4, ... = 我們填 DP table 的順序

Longest Increasing Subsequence:
  dp[i] = max(dp[j] + 1) for all j < i where nums[j] < nums[i]

  DAG: 每個 index 是節點
       如果 j < i 且 nums[j] < nums[i]，有邊 j → i
       dp[i] = 從任何起點到 i 的最長路徑

  LIS 的答案 = DAG 上的最長路徑！
```

### 最終統一圖

```
                        ┌─── Brute Force（遍歷所有）
                        │
                   ┌────┤
                   │    └─── Backtracking（DFS + 剪枝）
                   │
                   │         ┌─── BFS = 最短路（unweighted）
     Graph         │    ┌────┤
     Problems ─────┤    │    └─── Dijkstra = 最短路（weighted）
                   │    │
                   ├────┤    ┌─── DFS (recursion or stack)
                   │    │    │
                   │    └────┤
                   │         └─── Union-Find (connectivity)
                   │
                   │         ┌─── DP = 最優路徑 on DAG
                   └────┬────┤
                        │    └─── Greedy = DP 的快捷方式
                        │         （當局部最優 = 全域最優時）
                        │
                        └─── Binary Search on Answer
                              （猜答案 + check function）
```

### 最終心法

```
面對任何 LeetCode 問題，問自己：

1.「這題的圖長什麼樣？」
   → 節點是什麼？邊是什麼？

2.「這題在問圖的什麼性質？」
   → 最短路？連通性？所有路徑？最優值？

3.「哪種遍歷策略最適合這個圖的形狀？」
   → 線性有序 → Binary Search / Two Pointers
   → DAG → DP (拓撲序)
   → 一般圖 → BFS / DFS
   → 需要所有解 → Backtracking (DFS)
   → 動態連通 → Union-Find

當你能這樣思考時，你看到的不再是 20 種不同的算法，
而是同一種思想的 20 種面貌。

算法之間不是獨立的島嶼 — 它們是同一片大陸的不同山峰。
站得夠高，你就能看見它們之間的連結。
```

---

## 附錄：等價關係速查表

| 連結 | 算法 A | 算法 B | 等價條件 | 經典例題 |
|------|--------|--------|---------|---------|
| 1 | BFS | DP | 狀態空間可線性化，求最少步數 | Coin Change, Jump Game II |
| 2 | DFS (遞迴) | DFS (迭代 Stack) | 永遠等價 | 所有 Tree/Graph Traversal |
| 3 | Backtracking | DFS | Backtracking = DFS + undo | Subsets, Permutations, N-Queens |
| 4 | Greedy | DP | Greedy Choice Property 成立 | Jump Game, Activity Selection |
| 5 | Binary Search on Answer | Greedy + 二分 | 答案空間單調 | Koko Eating Bananas, Split Array |
| 6 | Union-Find | DFS/BFS | 靜態圖 = 等價；動態圖 = UF 更強 | Number of Islands |
| 7 | Monotonic Stack | DP (邊界計算) | 求「最近的更大/更小」 | Largest Rectangle in Histogram |
| 8 | Prefix Sum + HashMap | Two Sum 變體 | 子陣列和 = 兩點差 | Subarray Sum Equals K |
| 9 | Top-down DP | Bottom-up DP | 永遠等價（只是遍歷方向不同） | 所有 DP 問題 |
| 10 | DP on DAG | Graph 最短/最長路徑 | DP table = DAG 節點 | LIS, 所有 DP |

> **如果你只記得一句話：**
> 所有算法都是在某個搜尋空間中，用某種策略尋找答案。
> 差別只在空間的形狀和策略的選擇。理解這個，你就理解了 LeetCode 的本質。
