# 第二章：條件機率與貝氏定理

> 台大機率統計教學講義
> 本章目標：從條件機率出發，推導全概率公式和貝氏定理，並學會「正向」vs「反向」的思考方式。

---

## 1. 條件機率的定義與直觀

### 1.1 定義

**條件機率（Conditional Probability）：** 在已知事件 $B$ 發生的前提下，事件 $A$ 發生的機率，記為 $P(A|B)$。

$$\boxed{P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) > 0}$$

### 1.2 直觀解釋

想像樣本空間 $\Omega$ 是一個大圓圈。當我們知道 $B$ 已經發生了，我們的「世界」就從 $\Omega$ 縮小成 $B$。在這個縮小的世界裡，$A$ 能佔多少比例？就是 $A \cap B$ 在 $B$ 中的佔比。

用面積來想：
$$P(A|B) = \frac{\text{A 和 B 重疊的面積}}{\text{B 的面積}}$$

### 1.3 條件機率也是合法的機率

$P(\cdot | B)$ 滿足 Kolmogorov 的三條公設（可以驗證），所以所有機率的性質對條件機率都成立。例如：

- $P(A^c | B) = 1 - P(A | B)$
- $P(A_1 \cup A_2 | B) = P(A_1 | B) + P(A_2 | B) - P(A_1 \cap A_2 | B)$
- $0 \leq P(A|B) \leq 1$
- $P(\Omega | B) = 1$

### 1.4 注意事項

- $P(A|B)$ 和 $P(B|A)$ 通常**不相等**！（這是最常見的錯誤之一）
- $P(A|B)$ 沒有定義當 $P(B) = 0$ 時
- 條件機率不是「A 和 B 同時發生的機率」，那是 $P(A \cap B)$

---

## 2. 乘法規則（Multiplication Rule）

### 2.1 兩個事件

直接從條件機率的定義移項：

$$\boxed{P(A \cap B) = P(B) \cdot P(A|B) = P(A) \cdot P(B|A)}$$

**口語：** 兩件事同時發生的機率 = 第一件發生的機率 × 在第一件已發生下第二件發生的機率。

### 2.2 多個事件的鏈式法則（Chain Rule）

$$P(A_1 \cap A_2 \cap \cdots \cap A_n) = P(A_1) \cdot P(A_2 | A_1) \cdot P(A_3 | A_1 \cap A_2) \cdots P(A_n | A_1 \cap \cdots \cap A_{n-1})$$

**推導（n = 3 的情況）：**

$$P(A_1 \cap A_2 \cap A_3) = P(A_3 | A_1 \cap A_2) \cdot P(A_1 \cap A_2)$$
$$= P(A_3 | A_1 \cap A_2) \cdot P(A_2 | A_1) \cdot P(A_1) \quad \blacksquare$$

一般情況用數學歸納法即可推廣。

**這個公式超級好用！** 很多「連續步驟」的機率問題都是用它來算的。

---

## 3. 全概率公式（Law of Total Probability）

### 3.1 定義與推導

**前提：** 事件 $B_1, B_2, \ldots, B_n$ 構成樣本空間 $\Omega$ 的一個**分割**（partition），意思是：
1. $B_i$ 兩兩互斥：$B_i \cap B_j = \emptyset$，$\forall i \neq j$
2. 窮舉：$\bigcup_{i=1}^{n} B_i = \Omega$
3. $P(B_i) > 0$，$\forall i$

**全概率公式：**

$$\boxed{P(A) = \sum_{i=1}^{n} P(A | B_i) \cdot P(B_i)}$$

**推導：**

因為 $B_1, \ldots, B_n$ 是分割，所以：
$$A = A \cap \Omega = A \cap (B_1 \cup B_2 \cup \cdots \cup B_n) = (A \cap B_1) \cup (A \cap B_2) \cup \cdots \cup (A \cap B_n)$$

而且 $A \cap B_1, A \cap B_2, \ldots, A \cap B_n$ 兩兩互斥（因為 $B_i$ 兩兩互斥）。

由可數可加性（公設三）：
$$P(A) = \sum_{i=1}^{n} P(A \cap B_i) = \sum_{i=1}^{n} P(A | B_i) \cdot P(B_i) \quad \blacksquare$$

### 3.2 直觀理解

全概率公式的精神就是「分情況討論」。

想像你要算「明天遲到的機率」。你不知道怎麼直接算，但你知道：
- 如果下雨（機率 40%），遲到的機率是 50%
- 如果不下雨（機率 60%），遲到的機率是 10%

那麼：
$$P(\text{遲到}) = P(\text{遲到} | \text{雨}) \cdot P(\text{雨}) + P(\text{遲到} | \text{不雨}) \cdot P(\text{不雨})$$
$$= 0.5 \times 0.4 + 0.1 \times 0.6 = 0.20 + 0.06 = 0.26$$

### 3.3 何時使用全概率公式？

**使用時機：** 直接算 $P(A)$ 很難，但如果按某種分類（分割）來分情況計算就很容易。

**關鍵線索：**
- 題目有「分階段」的結構（先...再...）
- 題目有「分類」的結構（如果是 type 1...如果是 type 2...）
- 你知道各分類下的條件機率和分類的機率

---

## 4. 貝氏定理（Bayes' Theorem）

### 4.1 推導

**動機：** 我們知道 $P(A|B_i)$（在各分類下，$A$ 的機率），但想反過來求 $P(B_j|A)$（觀察到 $A$ 之後，是哪個分類的機率）。

$$P(B_j | A) = \frac{P(A \cap B_j)}{P(A)} = \frac{P(A | B_j) \cdot P(B_j)}{P(A)}$$

用全概率公式展開分母：

$$\boxed{P(B_j | A) = \frac{P(A | B_j) \cdot P(B_j)}{\sum_{i=1}^{n} P(A | B_i) \cdot P(B_i)}}$$

### 4.2 術語

在貝氏定理中：
- $P(B_j)$：**先驗機率（prior probability）** — 在看到任何資料之前，對 $B_j$ 的信念
- $P(A | B_j)$：**似然度（likelihood）** — 如果 $B_j$ 為真，觀察到 $A$ 的可能性
- $P(B_j | A)$：**後驗機率（posterior probability）** — 看到資料 $A$ 之後，更新的信念
- $P(A)$：**證據（evidence / marginal likelihood）** — 正規化常數

**口訣：**
$$\text{後驗} = \frac{\text{似然} \times \text{先驗}}{\text{證據}} \quad \Leftrightarrow \quad \text{Posterior} \propto \text{Likelihood} \times \text{Prior}$$

### 4.3 「正向」vs「反向」思考

**全概率公式 = 正向思考：** 知道原因的分布，推論結果的機率。

$$\text{原因} \xrightarrow{P(A|B_i)} \text{結果}$$

- 已知：各種原因（分類）的機率 $P(B_i)$ 和各原因下結果的機率 $P(A|B_i)$
- 求：結果 $A$ 的總機率 $P(A)$

**貝氏定理 = 反向思考：** 觀察到結果，反推原因的機率。

$$\text{結果} \xrightarrow{P(B_j|A)} \text{原因}$$

- 已知：結果 $A$ 已經發生
- 求：是哪個原因 $B_j$ 造成的？

**何時用全概率？** 要算「結果」的機率時。

**何時用貝氏？** 觀察到結果後，要反推「原因」時。

---

## 5. 獨立性（Independence）

### 5.1 定義

兩個事件 $A$ 和 $B$ **獨立**（independent），若且唯若：
$$\boxed{P(A \cap B) = P(A) \cdot P(B)}$$

等價條件（當 $P(B) > 0$ 時）：
$$P(A | B) = P(A)$$

直觀：知道 $B$ 是否發生，完全不影響 $A$ 發生的機率。

### 5.2 多事件的獨立性

$A_1, A_2, \ldots, A_n$ **互相獨立**（mutually independent），若對所有子集 $\{i_1, i_2, \ldots, i_k\} \subseteq \{1, 2, \ldots, n\}$，都有：
$$P(A_{i_1} \cap A_{i_2} \cap \cdots \cap A_{i_k}) = P(A_{i_1}) \cdot P(A_{i_2}) \cdots P(A_{i_k})$$

**注意：** 兩兩獨立（pairwise independence）不等於互相獨立（mutual independence）！

**反例：** 擲一枚公平硬幣兩次。令：
- $A$ = 第一次是 H
- $B$ = 第二次是 H
- $C$ = 兩次結果相同

可以驗證 $A, B, C$ 兩兩獨立（每對的交集機率 = 各自機率之積 = 1/4），但不是互相獨立的（因為 $P(A \cap B \cap C) = P(\{HH\}) = 1/4 \neq P(A) P(B) P(C) = 1/8$）。

### 5.3 獨立 vs 互斥

這兩個概念**完全不同**，新手最容易搞混！

| | 獨立 | 互斥（不相容） |
|---|---|---|
| 定義 | $P(A \cap B) = P(A) P(B)$ | $P(A \cap B) = 0$ |
| 直觀 | 兩者「互不影響」 | 兩者「不能同時發生」 |
| 一個發生時 | 不影響另一個的機率 | 另一個一定不發生 |
| 能同時成立？ | 除非某事件機率 = 0 | 除非某事件機率 = 0 |

**關鍵觀察：** 如果 $P(A) > 0$ 且 $P(B) > 0$，那麼互斥 $\Rightarrow$ 不獨立！

因為互斥意味 $P(A \cap B) = 0$，但獨立要求 $P(A \cap B) = P(A)P(B) > 0$。

### 5.4 獨立 vs 不相關（Uncorrelated）

「不相關」（uncorrelated）是針對隨機變數的概念：$\text{Cov}(X, Y) = 0$。

- 獨立 $\Rightarrow$ 不相關（獨立一定不相關）
- 不相關 $\not\Rightarrow$ 獨立（不相關不一定獨立）

**反例：** 令 $X \sim \text{Uniform}\{-1, 0, 1\}$，$Y = X^2$。

$E[XY] = E[X^3] = (-1)^3 \cdot \frac{1}{3} + 0^3 \cdot \frac{1}{3} + 1^3 \cdot \frac{1}{3} = 0$

$E[X]E[Y] = 0 \cdot E[X^2] = 0$

所以 $\text{Cov}(X,Y) = E[XY] - E[X]E[Y] = 0$，不相關。

但 $X$ 和 $Y$ 明顯不獨立（知道 $X = 0$ 就能確定 $Y = 0$）。

**結論：** 不相關只是「線性關係為零」，但可能有非線性的依賴。獨立是「完全沒有任何關係」。

---

## 6. 完整計算範例

### 範例 1：抽球問題（有放回 vs 無放回）

**問題：** 袋中有 5 紅球、3 白球。依序抽 2 球。

**（A）有放回抽樣：求兩球都是紅色的機率。**

因為有放回，兩次抽球獨立。

$$P(\text{兩紅}) = P(\text{第一紅}) \times P(\text{第二紅}) = \frac{5}{8} \times \frac{5}{8} = \frac{25}{64}$$

**（B）無放回抽樣：求兩球都是紅色的機率。**

兩次抽球不獨立，需用乘法規則。

$$P(\text{兩紅}) = P(\text{第一紅}) \times P(\text{第二紅} | \text{第一紅})$$
$$= \frac{5}{8} \times \frac{4}{7} = \frac{20}{56} = \frac{5}{14}$$

**（C）無放回抽樣：求第二球是紅色的機率。**

用全概率公式，按第一球的顏色分類：

$$P(\text{第二紅}) = P(\text{第二紅} | \text{第一紅}) \cdot P(\text{第一紅}) + P(\text{第二紅} | \text{第一白}) \cdot P(\text{第一白})$$
$$= \frac{4}{7} \times \frac{5}{8} + \frac{5}{7} \times \frac{3}{8}$$
$$= \frac{20}{56} + \frac{15}{56} = \frac{35}{56} = \frac{5}{8}$$

**有趣！** 第二球是紅色的機率 = 第一球是紅色的機率 = $5/8$！

這不是巧合。在無放回的隨機抽樣中，每個位置被抽到紅球的邊際機率都是 $5/8$。這個結論叫做**對稱性**（exchangeability），在很多問題中都很有用。

**（D）無放回：已知第二球是紅色，求第一球也是紅色的機率。**

用貝氏定理：
$$P(\text{第一紅} | \text{第二紅}) = \frac{P(\text{第二紅} | \text{第一紅}) \cdot P(\text{第一紅})}{P(\text{第二紅})}$$
$$= \frac{\frac{4}{7} \times \frac{5}{8}}{\frac{5}{8}} = \frac{4}{7}$$

直觀上也很合理：已知第二球是紅色，等於拿掉了一個紅球，剩下的 7 球中有 4 紅 3 白，第一球是紅色的機率就是 $4/7$。

---

### 範例 2：醫學檢測（Sensitivity/Specificity → PPV）

**問題：** 某疾病的盛行率（prevalence）是 0.1%（千分之一）。有一種檢測：
- Sensitivity（靈敏度）= $P(\text{檢測陽性} | \text{有病}) = 0.99$
- Specificity（特異度）= $P(\text{檢測陰性} | \text{沒病}) = 0.99$

一個人檢測結果為陽性，他真的有病的機率是多少？

**設定：**
- $D$ = 有病，$D^c$ = 沒病
- $+$ = 檢測陽性，$-$ = 檢測陰性
- $P(D) = 0.001$，$P(D^c) = 0.999$
- $P(+ | D) = 0.99$（sensitivity）
- $P(- | D^c) = 0.99$，所以 $P(+ | D^c) = 0.01$（false positive rate = 1 - specificity）

**要求：** $P(D | +)$（Positive Predictive Value, PPV）

**用貝氏定理：**

$$P(D | +) = \frac{P(+ | D) \cdot P(D)}{P(+)}$$

先用全概率公式算 $P(+)$：
$$P(+) = P(+ | D) \cdot P(D) + P(+ | D^c) \cdot P(D^c)$$
$$= 0.99 \times 0.001 + 0.01 \times 0.999$$
$$= 0.00099 + 0.00999 = 0.01098$$

代入：
$$P(D | +) = \frac{0.00099}{0.01098} = 0.0901 \approx 9\%$$

**驚人的結果：** 即使檢測的準確率高達 99%，當疾病盛行率很低（0.1%）時，檢測陽性的人真的有病的機率只有 9%！

**為什麼？** 因為在 10000 人中：
- 真正有病：10 人，其中 9.9 人檢測陽性（真陽性）
- 沒有病：9990 人，其中 99.9 人檢測陽性（假陽性）
- 總共陽性：約 109.8 人，其中只有 9.9 人真的有病

假陽性的「人數」遠大於真陽性，因為沒病的人基數太大了！

**教訓：** 不能忽略 base rate（基率）！這就是所謂的 **base rate fallacy**。

---

### 範例 3：Monty Hall Problem

**問題：** 你參加遊戲節目，面前有三扇門（A、B、C）。其中一扇後面有汽車（獎品），其他兩扇後面是山羊。你選了 A 門。主持人（知道答案）打開了 B 門，裡面是山羊。他問你要不要換到 C 門。換門是否有利？

**設定：**
- $H_A$ = 車在 A 門，$H_B$ = 車在 B 門，$H_C$ = 車在 C 門
- 先驗：$P(H_A) = P(H_B) = P(H_C) = 1/3$
- 觀察到的事件：$O$ = 主持人打開 B 門（裡面是山羊）

**主持人開門的策略：** 主持人必然開一扇有山羊的門，且不會開你選的門。

- $P(O | H_A)$：車在 A（你選的），主持人可以開 B 或 C，假設隨機選一扇：$P(O | H_A) = 1/2$
- $P(O | H_B)$：車在 B，主持人不能開 B（有車），只能開 C。但他開了 B，矛盾！$P(O | H_B) = 0$
- $P(O | H_C)$：車在 C，主持人不能開 C（有車）也不能開 A（你選的），只能開 B：$P(O | H_C) = 1$

**用貝氏定理求後驗機率：**

$$P(H_A | O) = \frac{P(O | H_A) \cdot P(H_A)}{P(O)} = \frac{\frac{1}{2} \cdot \frac{1}{3}}{P(O)} = \frac{1/6}{P(O)}$$

$$P(H_C | O) = \frac{P(O | H_C) \cdot P(H_C)}{P(O)} = \frac{1 \cdot \frac{1}{3}}{P(O)} = \frac{1/3}{P(O)}$$

$$P(H_B | O) = 0$$

因為後驗必須相加為 1：
$$P(H_A | O) + P(H_C | O) = 1$$
$$\frac{1/6 + 1/3}{P(O)} = 1 \Rightarrow P(O) = 1/2$$

所以：
$$P(H_A | O) = \frac{1/6}{1/2} = \frac{1}{3}, \quad P(H_C | O) = \frac{1/3}{1/2} = \frac{2}{3}$$

**結論：換門的勝率是 2/3，不換的勝率是 1/3。應該換！**

**直觀理解：** 你一開始選對的機率是 1/3。主持人開門不會改變這個事實。所以車在另外兩扇門的機率仍然是 2/3，而現在已知 B 不是了，所以這 2/3 全集中到 C 門。

---

### 範例 4：多次條件更新（Sequential Bayesian Update）

**問題：** 有兩個硬幣：硬幣 A（正面機率 0.7）和硬幣 B（正面機率 0.4）。隨機選一個硬幣（各 50% 機率），然後連續擲兩次。第一次是正面，第二次是反面。問拿到的是硬幣 A 的機率。

**解法：逐步更新**

**Step 1：先驗**
$$P(\text{A}) = P(\text{B}) = 0.5$$

**Step 2：第一次觀察——正面（H）**

更新後驗：
$$P(\text{A} | H_1) = \frac{P(H_1 | \text{A}) \cdot P(\text{A})}{P(H_1 | \text{A}) \cdot P(\text{A}) + P(H_1 | \text{B}) \cdot P(\text{B})}$$
$$= \frac{0.7 \times 0.5}{0.7 \times 0.5 + 0.4 \times 0.5} = \frac{0.35}{0.35 + 0.20} = \frac{0.35}{0.55} = \frac{7}{11} \approx 0.6364$$

看到正面後，更相信是硬幣 A（因為 A 出正面機率較高）。

**Step 3：第二次觀察——反面（T）**

現在的「先驗」是上一步的後驗：$P(\text{A}) = 7/11$，$P(\text{B}) = 4/11$。

$$P(\text{A} | H_1, T_2) = \frac{P(T_2 | \text{A}) \cdot P(\text{A} | H_1)}{P(T_2 | \text{A}) \cdot P(\text{A} | H_1) + P(T_2 | \text{B}) \cdot P(\text{B} | H_1)}$$
$$= \frac{0.3 \times \frac{7}{11}}{0.3 \times \frac{7}{11} + 0.6 \times \frac{4}{11}}$$
$$= \frac{\frac{2.1}{11}}{\frac{2.1}{11} + \frac{2.4}{11}} = \frac{2.1}{2.1 + 2.4} = \frac{2.1}{4.5} = \frac{21}{45} = \frac{7}{15} \approx 0.4667$$

**驗證：一次性計算（應該得到一樣的結果）**

$$P(\text{A} | H_1, T_2) = \frac{P(H_1, T_2 | \text{A}) \cdot P(\text{A})}{P(H_1, T_2 | \text{A}) \cdot P(\text{A}) + P(H_1, T_2 | \text{B}) \cdot P(\text{B})}$$

因為每次擲硬幣（給定是哪一枚硬幣）是獨立的：
$$P(H_1, T_2 | \text{A}) = 0.7 \times 0.3 = 0.21$$
$$P(H_1, T_2 | \text{B}) = 0.4 \times 0.6 = 0.24$$

$$P(\text{A} | H_1, T_2) = \frac{0.21 \times 0.5}{0.21 \times 0.5 + 0.24 \times 0.5} = \frac{0.105}{0.105 + 0.120} = \frac{0.105}{0.225} = \frac{7}{15} \approx 0.4667 \checkmark$$

兩種方法得到相同答案！Sequential update 的好處是你每看到一個新資料就可以更新一次，不需要全部重算。

---

### 範例 5：獨立性判斷

**問題：** 擲兩顆公平骰子。定義以下事件：
- $A$ = 第一顆是偶數
- $B$ = 兩顆的和是偶數
- $C$ = 兩顆的和 $\geq 8$

判斷 $A, B$ 是否獨立？$A, C$ 是否獨立？$B, C$ 是否獨立？

**分析（樣本空間有 36 個等可能結果）：**

**$P(A)$：** 第一顆是偶數（2, 4, 6），共 18 個結果。$P(A) = 18/36 = 1/2$。

**$P(B)$：** 和是偶數。和是偶數 $\iff$ 兩顆都是偶數或都是奇數。
- 都偶：$3 \times 3 = 9$ 種
- 都奇：$3 \times 3 = 9$ 種
- 共 18 種。$P(B) = 18/36 = 1/2$。

**$P(C)$：** 和 $\geq 8$。列舉：
- 和 = 8：(2,6)(3,5)(4,4)(5,3)(6,2) = 5 種
- 和 = 9：(3,6)(4,5)(5,4)(6,3) = 4 種
- 和 = 10：(4,6)(5,5)(6,4) = 3 種
- 和 = 11：(5,6)(6,5) = 2 種
- 和 = 12：(6,6) = 1 種
- 共 15 種。$P(C) = 15/36 = 5/12$。

**判斷 A 和 B：**

$A \cap B$ = 第一顆是偶數且和是偶數 = 第一顆偶數且第二顆也是偶數 = $3 \times 3 = 9$ 種。

$P(A \cap B) = 9/36 = 1/4$

$P(A) \cdot P(B) = 1/2 \times 1/2 = 1/4$

$P(A \cap B) = P(A) \cdot P(B)$ ✓ → **A 和 B 獨立**

**判斷 A 和 C：**

$A \cap C$ = 第一顆偶數且和 $\geq 8$。列舉第一顆 = 2, 4, 6 的情況：
- 第一顆 = 2：第二顆 $\geq 6$，即 (2,6)，1 種
- 第一顆 = 4：第二顆 $\geq 4$，即 (4,4)(4,5)(4,6)，3 種
- 第一顆 = 6：第二顆 $\geq 2$，即 (6,2)(6,3)(6,4)(6,5)(6,6)，5 種
- 共 9 種。$P(A \cap C) = 9/36 = 1/4$

$P(A) \cdot P(C) = 1/2 \times 5/12 = 5/24 \approx 0.2083$

$P(A \cap C) = 1/4 = 0.25 \neq 5/24$ → **A 和 C 不獨立**

直觀：知道第一顆是偶數（特別是 6），會增加和 $\geq 8$ 的機率，所以不獨立。

**判斷 B 和 C：**

$B \cap C$ = 和是偶數且 $\geq 8$，即和 = 8, 10, 12。
- 和 = 8：5 種
- 和 = 10：3 種
- 和 = 12：1 種
- 共 9 種。$P(B \cap C) = 9/36 = 1/4$

$P(B) \cdot P(C) = 1/2 \times 5/12 = 5/24$

$1/4 \neq 5/24$ → **B 和 C 不獨立**

---

### 範例 6：經典陷阱——Boy or Girl Paradox

**問題版本 1：** 一個家庭有兩個小孩。已知至少有一個男孩。兩個都是男孩的機率是多少？

**解：** 樣本空間（不考慮出生順序無所謂，但考慮順序更清楚）：

$\Omega = \{BB, BG, GB, GG\}$

$A$ = 至少一個男孩 = $\{BB, BG, GB\}$
$C$ = 兩個都是男孩 = $\{BB\}$

$$P(C | A) = \frac{P(C \cap A)}{P(A)} = \frac{1/4}{3/4} = \frac{1}{3}$$

**問題版本 2：** 一個家庭有兩個小孩。已知**老大**是男孩。兩個都是男孩的機率？

$B$ = 老大是男孩 = $\{BB, BG\}$

$$P(C | B) = \frac{P(C \cap B)}{P(B)} = \frac{1/4}{2/4} = \frac{1}{2}$$

**注意差異！** 「至少一個男孩」給的資訊比「老大是男孩」少，所以得到的機率不同。

**常見錯誤：** 混淆這兩個版本，以為答案都是 1/2。

---

## 7. 常見陷阱彙整

### 陷阱 1：混淆 P(A|B) 和 P(B|A)

$$P(\text{感冒} | \text{咳嗽}) \neq P(\text{咳嗽} | \text{感冒})$$

感冒的人大多會咳嗽 → $P(\text{咳嗽} | \text{感冒})$ 大
但咳嗽的人不一定是感冒（可能是過敏、抽菸...）→ $P(\text{感冒} | \text{咳嗽})$ 不一定大

**這叫做 Prosecutor's Fallacy（檢察官謬誤）：**
$$P(\text{證據} | \text{無罪}) \text{ 很小} \not\Rightarrow P(\text{無罪} | \text{證據}) \text{ 很小}$$

### 陷阱 2：忽略 Base Rate

如範例 2 所示，即使檢測很準，如果疾病很罕見，陽性結果的 PPV 可能很低。

永遠要考慮先驗機率！

### 陷阱 3：把不獨立的事件當獨立

**例子：** 不放回抽樣中，連續兩次的結果**不獨立**。

**錯：** $P(\text{第一紅且第二紅}) = P(\text{第一紅}) \times P(\text{第二紅}) = (5/8)^2$

**對：** $P(\text{第一紅且第二紅}) = P(\text{第一紅}) \times P(\text{第二紅} | \text{第一紅}) = 5/8 \times 4/7$

### 陷阱 4：條件機率的「縮小世界」

計算 $P(A | B)$ 時，分母是 $P(B)$，不是 $P(\Omega) = 1$。

這意味著你是在 $B$ 的世界裡看 $A$ 的比例，不是在整個 $\Omega$ 的世界裡。

### 陷阱 5：全概率公式的分割不完整

使用全概率公式時，$B_1, B_2, \ldots, B_n$ 必須構成完整的分割（互斥且窮舉）。如果漏了某些情況，結果就會錯。

---

## 8. 總結比較表

| 概念 | 公式 | 使用時機 |
|------|------|----------|
| 條件機率 | $P(A\|B) = \frac{P(A \cap B)}{P(B)}$ | 在已知 B 下求 A 的機率 |
| 乘法規則 | $P(A \cap B) = P(A) \cdot P(B\|A)$ | 求兩事件同時發生的機率 |
| 全概率公式 | $P(A) = \sum_i P(A\|B_i) P(B_i)$ | 分情況算某事件的總機率（正向） |
| 貝氏定理 | $P(B_j\|A) = \frac{P(A\|B_j) P(B_j)}{\sum_i P(A\|B_i) P(B_i)}$ | 觀察到結果，反推原因（反向） |
| 獨立 | $P(A \cap B) = P(A) P(B)$ | 兩事件互不影響 |

**解題策略：**
1. 畫樹狀圖（probability tree）：視覺化很有幫助
2. 看到「在...的條件下」→ 條件機率
3. 看到「某事件的總機率」但有分類 → 全概率
4. 看到「已知結果，求原因」→ 貝氏定理
5. 先判斷是否獨立，再決定能不能直接乘

---

> 下一章：離散分布大全
