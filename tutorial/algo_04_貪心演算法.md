# 演算法教學 04：貪心演算法 (Greedy Algorithms)

> 台大資工演算法課程教學講義
> 本講義涵蓋：觀念解說、定理推導、虛擬碼、計算範例、何時使用、常見陷阱

---

## 本章基礎觀念（零基礎必讀）

### 為什麼需要學貪心演算法？

假設你去超市買東西，結帳時要找零 41 元。你手上有 25 元、10 元、5 元、1 元四種硬幣。你會怎麼找？

大部分人的直覺：**先用最大面額的硬幣，用不了再換小的**。
- 25 元 x 1 → 剩餘 16 元
- 10 元 x 1 → 剩餘 6 元
- 5 元 x 1 → 剩餘 1 元
- 1 元 x 1 → 剩餘 0 元
- 一共 4 枚硬幣

這就是「貪心演算法」——**每一步都做當下看起來最好的選擇**。在這個找零問題中，「最好的選擇」就是「用最大面額」。而且在這個特定的幣值系統中，這個策略確實能找到最少硬幣數！

但**貪心不是萬能的**。如果幣值系統是 {1, 3, 4}，要找零 6 元：
- 貪心：4 + 1 + 1 = 3 枚
- 最佳：3 + 3 = 2 枚
- 貪心失敗了！

所以學貪心演算法的重點不只是「怎麼用」，更是「什麼時候能用、什麼時候不能用、怎麼證明它是對的」。

### 本章關鍵術語表

| 術語 | 英文 | 白話解釋 | 例子 |
|------|------|----------|------|
| 貪心演算法 | Greedy Algorithm | 每一步都做當下看起來最好的選擇 | 找零時先用最大面額 |
| 貪心選擇性質 | Greedy Choice Property | 每一步的「最好選擇」一定出現在某個全域最佳解中 | 活動選擇中「選最早結束的」 |
| 最佳子結構 | Optimal Substructure | 大問題的最佳解 = 第一步的最佳選擇 + 剩餘子問題的最佳解 | 同 DP 所需的性質 |
| 交換論證 | Exchange Argument | 證明貪心正確的技巧：把最佳解中的元素換成貪心的，不會變差 | 見 3.1 節 |
| 貪心領先 | Greedy Stays Ahead | 證明貪心正確的技巧：證明每一步都至少跟最佳解一樣好 | 見 3.2 節 |
| 霍夫曼編碼 | Huffman Coding | 用貪心建最佳前綴碼，頻率高的字元編碼短 | 見 4.2 節 |
| 前綴碼 | Prefix-free Code | 沒有任何一個編碼是另一個的前綴 | 0, 10, 110, 111 |
| 擬陣 | Matroid | 判斷貪心一定有效的抽象數學結構 | 見第 7 節（進階） |

### 前置知識

- **DP 基礎**（algo_03）：理解什麼是 Optimal Substructure
- **排序**：很多 Greedy 演算法的第一步是排序
- **反例思維**：養成「看到一個策略先想反例」的習慣

---

## 目錄

1. [貪心演算法的框架和思路](#1-貪心演算法的框架和思路)
2. [Greedy 成立的兩個必要條件](#2-greedy-成立的兩個必要條件)
3. [Greedy 正確性的兩大證明技巧](#3-greedy-正確性的兩大證明技巧)
4. [經典 Greedy 問題](#4-經典-greedy-問題)
5. [Greedy 失敗的經典反例](#5-greedy-失敗的經典反例)
6. [看起來像 Greedy 但其實要用 DP 的判斷指南](#6-看起來像-greedy-但其實要用-dp-的判斷指南)
7. [Matroid 簡介 (Bonus)](#7-matroid-簡介-bonus)

---

## 1. 貪心演算法的框架和思路

### 1.1 核心精神

貪心演算法的想法非常直覺：**在每一步都做出「當下看起來最好」的選擇，然後祈禱這些局部最佳的選擇組合起來會變成全域最佳解。**

聽起來很天真，對吧？確實，很多時候這招是行不通的。但神奇的是，有一大類問題，這個天真的策略恰好就是對的。

### 1.2 一般框架

```
GREEDY-FRAMEWORK(問題 P):
    S ← ∅                           // 解集合初始化為空
    while 問題 P 尚未解完:
        x ← 從剩餘候選中選出「最好的」一個   // 貪心選擇
        if 把 x 加入 S 後仍然是可行解:
            S ← S ∪ {x}
    return S
```

這裡的關鍵在於「最好的」怎麼定義。不同問題有不同的貪心策略，而一個策略能不能用，需要嚴格的證明。

### 1.3 設計步驟

設計一個 Greedy 演算法通常遵循以下步驟：

1. **描述問題的最優子結構**：原問題的最優解包含子問題的最優解
2. **設計貪心策略**：決定每一步「怎麼選最好的」
3. **證明正確性**：用 Exchange Argument 或 Greedy Stays Ahead 證明
4. **分析複雜度**：通常 Greedy 的時間複雜度很漂亮

### 1.4 Greedy vs Dynamic Programming

先給一個直覺上的比較，後面會詳細展開：

| 面向 | Greedy | DP |
|------|--------|----|
| 選擇時機 | 做選擇**之前**不需要知道子問題的解 | 做選擇**之前**需要先解子問題 |
| 子問題數量 | 每步只產生**一個**子問題 | 每步可能產生**多個**子問題 |
| 回溯 | 永不回溯，選了就選了 | 考慮所有子問題的解再做選擇 |
| 效率 | 通常更快 | 通常需要更多空間和時間 |

---

## 2. Greedy 成立的兩個必要條件

一個問題能用 Greedy 正確解決，必須滿足以下兩個性質。

### 2.1 Greedy Choice Property（貪心選擇性質）

**定義**：我們可以透過做出局部最佳（貪心）選擇來達到全域最佳解。換句話說，存在一個最優解「包含」了我們的貪心選擇。

白話翻譯就是：**第一步做的貪心選擇不會把我們帶到死路上，一定存在某個全域最優解是從這個貪心選擇開始的。**

證明 Greedy Choice Property 的典型套路：
1. 假設有一個最優解 OPT，它**沒有**包含我們的貪心選擇
2. 證明可以把 OPT 修改成另一個解 OPT'，使得 OPT' 包含我們的貪心選擇
3. 證明 OPT' 至少跟 OPT 一樣好（不會變差）
4. 因此 OPT' 也是最優解，而且它包含了貪心選擇 → 得證

### 2.2 Optimal Substructure（最優子結構）

**定義**：做出貪心選擇之後，剩下的子問題的最優解，加上這個貪心選擇，就構成原問題的最優解。

白話翻譯就是：**大問題的最優解 = 第一步的貪心選擇 + 剩下子問題的最優解。**

這個性質其實 DP 也需要，所以光有最優子結構不夠——關鍵是你還需要 Greedy Choice Property。

### 2.3 兩者缺一不可

- **只有 Optimal Substructure 沒有 Greedy Choice Property**：你需要考慮所有可能的第一步選擇 → 這就是 DP
- **只有 Greedy Choice Property 沒有 Optimal Substructure**：你的第一步是對的，但後續子問題不能遞迴地用同樣方法處理
- **兩者都有**：恭喜，Greedy 可以用！

---

## 3. Greedy 正確性的兩大證明技巧

這是考試的重點中的重點。很多同學會「用」Greedy，但不會「證」Greedy。以下兩個技巧務必熟練。

### 3.1 Exchange Argument（交換論證）

#### 3.1.1 核心思想

假設存在一個最優解 OPT 跟你的 Greedy 解 G 不一樣，然後證明可以把 OPT 中的某個元素「交換」成 G 中的元素，而解不會變差。重複這個過程，最終把 OPT 變成 G，所以 G 也是最優解。

#### 3.1.2 完整框架（五步法）

**Step 1：定義**
- 令 G = (g₁, g₂, ..., gₙ) 為 Greedy 演算法產生的解
- 令 O = (o₁, o₂, ..., oₘ) 為任意一個最優解

**Step 2：找到第一個不同的地方**
- 找到最小的 index i，使得 gᵢ ≠ oᵢ
- （或者找到 G 有但 O 沒有的元素，反之亦然）

**Step 3：執行交換**
- 把 O 中的 oᵢ 替換成 gᵢ，得到新的解 O'
- （或者把 oᵢ 和 gᵢ 的位置對調）

**Step 4：證明交換後不會變差**
- 證明 O' 仍然是可行解（feasible）
- 證明 O' 的目標函數值 ≥ O 的值（如果是最大化問題）或 ≤（如果是最小化問題）

**Step 5：歸納結論**
- 因為 O' 至少跟 O 一樣好，而且 O' 跟 G 多了一個地方相同
- 重複這個交換過程，最終可以把 O 完全變成 G
- 所以 G 也是最優解

#### 3.1.3 Exchange Argument 填空式模板

> **給初學者**：每次要證明 Greedy 正確時，可以照著以下模板填空。
>
> ```
> 證明：Greedy 演算法產生最佳解
>
> Step 1（定義）：
>   令 G = __________ 為 Greedy 演算法產生的解
>   令 O = __________ 為任意一個最優解
>
> Step 2（找不同）：
>   找到第一個 G 和 O 不同的地方：__________
>
> Step 3（交換）：
>   把 O 中的 __________ 換成 G 中的 __________，得到新的解 O'
>
> Step 4（證明不變差）：
>   O' 仍然是可行解嗎？是，因為 __________
>   O' 的品質 ≥ O 嗎？是，因為 __________
>
> Step 5（結論）：
>   O' 至少跟 O 一樣好，而且 O' 跟 G 多了一個地方相同。
>   重複以上步驟，最終可以把 O 完全變成 G。
>   所以 G 也是最優解。QED
> ```

#### 3.1.4 完整範例：Activity Selection 的 Exchange Argument

**問題**：有 n 個活動，每個活動有開始時間 sᵢ 和結束時間 fᵢ。要選最多的互不重疊活動。

**Greedy 策略**：每次選結束時間最早的活動（不跟已選的衝突）。

**證明**：

令 G = {g₁, g₂, ..., gₖ} 為 Greedy 解（按結束時間排序），
令 O = {o₁, o₂, ..., oₘ} 為任意最優解（按結束時間排序）。

我們要證明 k = m（G 也是最優解）。

**Step 1**：考慮 O 中的第一個活動 o₁ 和 G 中的第一個活動 g₁。

**Step 2**：因為 Greedy 選的是結束最早的，所以 f(g₁) ≤ f(o₁)。

**Step 3**：把 O 中的 o₁ 換成 g₁，得到 O' = {g₁, o₂, ..., oₘ}。

**Step 4**：O' 是可行的嗎？
- g₁ 跟 o₂ 不衝突，因為 f(g₁) ≤ f(o₁) ≤ s(o₂)
- o₂ 到 oₘ 之間本來就不衝突
- 所以 O' 是可行的，而且 |O'| = |O| = m

**Step 5**：O' 也是最優解，但它的第一個活動跟 G 一樣了。

對 O' 和 G 的剩餘部分（扣掉第一個活動後的子問題）重複上述論證...

最終，可以把 O 完全變成 G，所以 |G| = |O| = m，G 是最優解。 QED

---

### 3.2 Greedy Stays Ahead（貪心領先）

#### 3.2.1 核心思想

證明 Greedy 的解在「每一步」都至少跟最優解一樣好。既然 Greedy 一路領先（或至少不落後），最終結果當然也至少跟最優解一樣好。

#### 3.2.2 完整框架（四步法）

**Step 1：定義衡量指標**
- 定義一個指標來衡量「在第 i 步，Greedy 做得多好」
- 例如：在第 i 步結束後，已選了幾個活動？已處理了多少工作量？

**Step 2：歸納假設**
- 假設在第 i 步，Greedy 的指標值至少跟最優解一樣好
- 形式上：對所有 j ≤ i，Greedy 在第 j 步的指標 ≥（或 ≤）最優解在第 j 步的指標

**Step 3：歸納步驟**
- 證明在第 i+1 步，Greedy 仍然領先
- 利用 Greedy 的選擇規則來論證

**Step 4：結論**
- 因為 Greedy 一路領先到最後，所以最終結果至少跟最優解一樣好
- 又因為最優解是最好的，所以 Greedy 的解恰好也是最優的

#### 3.2.3 完整範例：Activity Selection 的 Greedy Stays Ahead

**Claim**：對所有 i = 1, 2, ..., k，Greedy 選的第 i 個活動的結束時間 ≤ 最優解中第 i 個活動的結束時間。也就是 f(gᵢ) ≤ f(oᵢ)。

**Base Case** (i = 1)：
- Greedy 第一步選結束最早的活動
- 所以 f(g₁) ≤ f(o₁)（不管 o₁ 是誰）  ✓

**Inductive Step**：
- 假設 f(gᵢ) ≤ f(oᵢ)（歸納假設）
- 要證明 f(gᵢ₊₁) ≤ f(oᵢ₊₁)
- 因為 f(gᵢ) ≤ f(oᵢ) ≤ s(oᵢ₊₁)（oᵢ 和 oᵢ₊₁ 不衝突）
- 所以 oᵢ₊₁ 在 Greedy 選第 i+1 個活動時是一個合法的候選
- 但 Greedy 選的是所有合法候選中結束最早的
- 所以 f(gᵢ₊₁) ≤ f(oᵢ₊₁)  ✓

**結論**：
- Greedy 在每一步都至少跟 OPT 一樣好（結束得更早或一樣早）
- 假設 k < m（Greedy 選得比 OPT 少），那麼由 f(gₖ) ≤ f(oₖ) ≤ s(oₖ₊₁)
- 這表示 oₖ₊₁ 在 Greedy 做完第 k 步後仍然是合法候選
- 但 Greedy 在有合法候選時不會停止 → 矛盾！
- 所以 k ≥ m，又因為 OPT 是最優的所以 k ≤ m
- 因此 k = m。QED

---

### 3.3 兩種技巧的比較

| 面向 | Exchange Argument | Greedy Stays Ahead |
|------|-------------------|---------------------|
| 核心動作 | 把 OPT 的元素換成 Greedy 的元素 | 用歸納法證明每步都領先 |
| 適用場景 | 解是一個「集合」時特別好用 | 解是一個「序列」時特別好用 |
| 證明目標 | OPT 可以被改造成 Greedy 解 | Greedy 在每步的度量都不差於 OPT |
| 常見於 | Activity Selection, Huffman, Kruskal | Interval Scheduling, Job Scheduling |
| 考試出題率 | ★★★★★ 非常高 | ★★★★ 高 |

---

## 4. 經典 Greedy 問題

### 4.1 Activity Selection（活動選擇問題）

#### 4.1.1 問題定義

給定 n 個活動，每個活動 i 有開始時間 sᵢ 和結束時間 fᵢ（sᵢ < fᵢ）。兩個活動「相容」代表它們不重疊。目標是選出最多的互相相容的活動。

#### 4.1.2 為什麼選最早結束？——不同策略的比較

很多同學會直覺想到其他策略，但它們都是錯的。讓我們一一分析。

**策略 A：選最早開始的**
```
反例：
活動 1: |__________________________|  (0 ~ 100)
活動 2:   |---|                        (1 ~ 3)
活動 3:         |---|                  (4 ~ 6)
活動 4:               |---|            (7 ~ 9)

策略 A 選了活動 1（最早開始），只選到 1 個
最優解是活動 2, 3, 4，共 3 個
```

**策略 B：選最短的活動**
```
反例：
活動 1: |________|                     (0 ~ 5)
活動 2:       |--|                     (4 ~ 6)   ← 最短
活動 3:          |________|            (5 ~ 10)

策略 B 先選活動 2（最短），然後活動 1 和 3 都與它衝突，只選到 1 個
最優解是活動 1, 3，共 2 個
```

**策略 C：選衝突最少的活動**
```
反例（構造稍微複雜）：
Group 1:  |---|  |---|  |---|          (各自獨立的 3 個活動)
Bridge:        |___________|            (跨越中間，跟 Group 1 的後2個和 Group 2 的前2個衝突)
Group 2:              |---|  |---|  |---|  (各自獨立的 3 個活動)

Bridge 的衝突數 = 4，但 Group 1 和 Group 2 中間的活動衝突數可能更少
選了 Bridge 之後，就不能同時選 Group 1 和 Group 2 的所有活動
```

更具體的反例：

```
活動:  A  B  C  D  E  F  G  H  I  J  K
時間軸: |--|  |--|  |--|  |--|  |--|  |--|
              \  |---------|  /
               |------------|

其中 F 這個活動跟最多活動不衝突，但選了 F 之後會錯過更好的組合。
```

**策略 D：選最早結束的 ← 正確！**

直覺：選結束最早的活動，為後面的活動留下最多的時間空間。

#### 4.1.3 虛擬碼

```
ACTIVITY-SELECTION(S, F):
    // S[1..n]: 開始時間, F[1..n]: 結束時間
    // 假設已按結束時間排序: F[1] ≤ F[2] ≤ ... ≤ F[n]

    A ← {1}                    // 先選結束最早的活動 1
    last ← 1                   // last 記錄最後選的活動編號

    for i ← 2 to n:
        if S[i] ≥ F[last]:     // 活動 i 不跟最後選的衝突
            A ← A ∪ {i}
            last ← i

    return A
```

**時間複雜度**：排序 O(n log n) + 一次掃描 O(n) = **O(n log n)**

#### 4.1.4 計算範例（6 個活動完整展示）

> **給初學者**：以下用一個時間軸圖示，讓你「看見」每個活動的時間範圍，理解為什麼選最早結束的是好策略。

```
時間:  0  1  2  3  4  5  6  7  8  9
       |--|--|--|--|--|--|--|--|--|--|
活動 C: [===========]                   (0~6)
活動 A:    [======]                     (1~4)
活動 B:       [=====]                   (3~5)
活動 D:             [=====]             (5~7)
活動 E:       [===========]             (3~8)
活動 F:                [======]         (6~9)
```

```
活動:     A    B    C    D    E    F
開始 s:   1    3    0    5    3    6
結束 f:   4    5    6    7    8    9

Step 0: 按結束時間排序
        A(1,4)  B(3,5)  C(0,6)  D(5,7)  E(3,8)  F(6,9)

Step 1: 選 A (f=4)，A = {A}，last_finish = 4
Step 2: 看 B: s=3 < 4 = last_finish → 衝突，跳過
Step 3: 看 C: s=0 < 4 = last_finish → 衝突，跳過
Step 4: 看 D: s=5 ≥ 4 = last_finish → 選！A = {A, D}，last_finish = 7
Step 5: 看 E: s=3 < 7 = last_finish → 衝突，跳過
Step 6: 看 F: s=6 < 7 = last_finish → 衝突，跳過

結果: A = {A, D}，選了 2 個活動
```

#### 4.1.5 正確性證明

（見 3.1.4 和 3.2.3，已用兩種方法分別證明）

---

### 4.2 Huffman Coding（霍夫曼編碼）

#### 4.2.1 問題定義

給定一組字元及其出現頻率，設計一個前綴碼（prefix-free code），使得編碼後的總長度最短。

前綴碼：任何一個字元的編碼都不是另一個字元編碼的前綴。這保證解碼時不會有歧義。

#### 4.2.2 Greedy 策略

**核心想法**：頻率越高的字元，編碼應該越短。

**Huffman 的貪心策略**：每次合併頻率最低的兩個節點。

#### 4.2.3 虛擬碼

```
HUFFMAN(C):
    // C: 字元集合，每個字元 c 有頻率 c.freq
    n ← |C|
    Q ← 建立一個 min-priority queue，包含 C 中所有字元

    for i ← 1 to n - 1:
        z ← 新建一個節點
        z.left ← x ← EXTRACT-MIN(Q)
        z.right ← y ← EXTRACT-MIN(Q)
        z.freq ← x.freq + y.freq
        INSERT(Q, z)

    return EXTRACT-MIN(Q)    // 最後剩下的就是根節點
```

**時間複雜度**：n-1 次迴圈，每次 EXTRACT-MIN 和 INSERT 各 O(log n) = **O(n log n)**

#### 4.2.4 手動建 Huffman Tree 範例

**例題**：字元頻率如下

| 字元 | a | b | c | d | e | f |
|------|---|---|---|---|---|---|
| 頻率 | 45 | 13 | 12 | 16 | 9 | 5 |

**Step 1**：初始 priority queue（按頻率排序）
```
Q: [f:5, e:9, c:12, b:13, d:16, a:45]
```

**Step 2**：取出 f(5) 和 e(9)，合併為節點 (14)
```
    (14)
   /    \
  f:5   e:9

Q: [c:12, b:13, (14), d:16, a:45]
```

**Step 3**：取出 c(12) 和 b(13)，合併為節點 (25)
```
    (25)
   /    \
  c:12  b:13

Q: [(14), d:16, (25), a:45]
```

**Step 4**：取出 (14) 和 d(16)，合併為節點 (30)
```
      (30)
     /    \
   (14)   d:16
   / \
  f:5 e:9

Q: [(25), (30), a:45]
```

**Step 5**：取出 (25) 和 (30)，合併為節點 (55)
```
          (55)
        /      \
     (25)      (30)
    /    \    /    \
  c:12 b:13 (14) d:16
             / \
           f:5 e:9

Q: [a:45, (55)]
```

**Step 6**：取出 a(45) 和 (55)，合併為根節點 (100)
```
              (100)
            /       \
         a:45       (55)
                  /      \
               (25)      (30)
              /    \    /    \
            c:12 b:13 (14) d:16
                       / \
                     f:5 e:9
```

**最終編碼**（左 0 右 1）：
| 字元 | 編碼 | 長度 |
|------|------|------|
| a | 0 | 1 |
| c | 100 | 3 |
| b | 101 | 3 |
| f | 1100 | 4 |
| e | 1101 | 4 |
| d | 111 | 3 |

**加權路徑長度** = 45×1 + 12×3 + 13×3 + 5×4 + 9×4 + 16×3 = 45 + 36 + 39 + 20 + 36 + 48 = **224**

#### 4.2.5 正確性證明（Exchange Argument）

**引理 1**：最優前綴碼中，頻率最低的兩個字元一定在最深層，而且是兄弟節點。

**證明**：
- 假設最優樹 T 中，頻率最低的兩個字元 x, y 不是最深層的兄弟
- 令 a, b 是 T 中最深層的兩個兄弟節點
- 因為 a, b 在最深層，它們的深度最大
- 交換 x 和 a：因為 freq(x) ≤ freq(a) 且 depth(x) ≤ depth(a)，交換後加權路徑長度：

  cost(T') - cost(T) = (freq(x) - freq(a)) × (depth(a) - depth(x)) ≤ 0

  所以 T' 不比 T 差
- 類似地交換 y 和 b，也不會變差
- 所以存在一個最優解，x 和 y 是兄弟 → Greedy Choice Property 成立

**引理 2（Optimal Substructure）**：合併 x 和 y 為新節點 z（freq(z) = freq(x) + freq(y)）後的子問題的最優解，加上 x, y 的分支，就是原問題的最優解。

**證明**：設 T 是原問題的最優樹，其中 x, y 是兄弟。令 T' 是將 x, y 替換為 z 後的樹。

cost(T) = cost(T') + freq(x) + freq(y)

所以最小化 cost(T) 等價於最小化 cost(T')。QED

#### 4.2.6 Ternary Huffman Coding（三元霍夫曼編碼）

如果每個節點有 3 個子節點（對應 0, 1, 2 三個符號），怎麼建樹？

**關鍵差異**：二元 Huffman 每次合併 2 個，n 個字元需要 n-1 次合併。三元 Huffman 每次合併 3 個，需要確保最後恰好合併完。

**問題**：如果 n 個字元，每次合併 3 個變 1 個（減少 2 個），那 n-1 必須是 2 的倍數，也就是 **n 必須是奇數**。

如果 n 是偶數，需要先補一個頻率為 0 的虛擬字元，使字元數變奇數。

更一般地：對 k-ary Huffman，需要 (n-1) mod (k-1) = 0。如果不滿足，補虛擬字元直到滿足。

**三元 Huffman 範例**：

字元頻率：A:15, B:7, C:6, D:6, E:5

n = 5，(5-1) mod (3-1) = 0 ✓ 不需要補虛擬字元

```
Step 1: Q = [E:5, C:6, D:6, B:7, A:15]
        合併 E(5), C(6), D(6) → (17)
        Q = [B:7, A:15, (17)]

Step 2: Q = [B:7, A:15, (17)]
        合併 B(7), A(15), (17) → (39)
        Q = [(39)]

最終樹:
              (39)
           /   |   \
         B:7  A:15  (17)
                   / | \
                 E:5 C:6 D:6

編碼（用 0, 1, 2）：
B: 0    (長度 1)
A: 1    (長度 1)
E: 20   (長度 2)
C: 21   (長度 2)
D: 22   (長度 2)

加權路徑長度 = 7×1 + 15×1 + 5×2 + 6×2 + 6×2 = 7 + 15 + 10 + 12 + 12 = 56
```

若 n = 6（偶數），(6-1) mod 2 = 1 ≠ 0，需要補 1 個頻率為 0 的虛擬字元使 n = 7（(7-1) mod 2 = 0 ✓）。

---

### 4.3 Fractional Knapsack（分數背包問題）

#### 4.3.1 問題定義

有 n 個物品，第 i 個物品重量 wᵢ，價值 vᵢ。背包容量為 W。每個物品可以取「一部分」（0 到 1 之間的任意比例）。目標是最大化背包中物品的總價值。

#### 4.3.2 Greedy 策略

按「單位重量的價值」(vᵢ/wᵢ) 由大到小排序，盡量多拿 CP 值最高的物品。

#### 4.3.3 虛擬碼

```
FRACTIONAL-KNAPSACK(v, w, W):
    // v[1..n]: 價值, w[1..n]: 重量, W: 背包容量

    // 按 v[i]/w[i] 降序排序
    按 v[i]/w[i] 對物品排序（降序）

    remaining ← W          // 剩餘容量
    total_value ← 0

    for i ← 1 to n:
        if w[i] ≤ remaining:
            // 整個物品都放進去
            total_value ← total_value + v[i]
            remaining ← remaining - w[i]
        else:
            // 只能放一部分
            fraction ← remaining / w[i]
            total_value ← total_value + fraction × v[i]
            remaining ← 0
            break

    return total_value
```

**時間複雜度**：排序 O(n log n) + 掃描 O(n) = **O(n log n)**

#### 4.3.4 計算範例

```
物品:     A      B      C
重量 w:   10     20     30
價值 v:   60     100    120
v/w:      6      5      4

背包容量 W = 50

Step 1: 按 v/w 排序：A(6), B(5), C(4)

Step 2: 拿物品 A（整個）
        total_value = 60, remaining = 50 - 10 = 40

Step 3: 拿物品 B（整個）
        total_value = 60 + 100 = 160, remaining = 40 - 20 = 20

Step 4: 拿物品 C 的 20/30 = 2/3
        total_value = 160 + (2/3)×120 = 160 + 80 = 240, remaining = 0

結果: 最大價值 = 240
```

#### 4.3.5 和 0/1 Knapsack 的比較

| 面向 | Fractional Knapsack | 0/1 Knapsack |
|------|---------------------|--------------|
| 物品可否分割 | 可以取任意比例 | 只能取或不取 |
| Greedy 有效？ | 有效 | **無效** |
| 為什麼？ | 可以精確填滿剩餘空間 | 可能有「浪費空間」的問題 |
| 正確方法 | Greedy (按 v/w 排序) | DP |
| 時間複雜度 | O(n log n) | O(nW) 偽多項式 |

**為什麼 0/1 Knapsack 不能用 Greedy？一個反例：**

```
物品:     A      B
重量 w:   10     20
價值 v:   60     100
v/w:      6      5

背包容量 W = 20

Greedy（按 v/w）: 選 A（w=10, v=60），剩餘容量 10
                  B 太重放不下 → 總價值 = 60

最優解: 選 B（w=20, v=100）→ 總價值 = 100

Greedy 給出 60，最優解是 100！
```

**直覺解釋**：Fractional Knapsack 能用 Greedy 是因為你可以把物品切開，所以不會「浪費」背包空間。但 0/1 Knapsack 不能切，選了一個 CP 值高但很輕的物品後，剩下的空間可能放不下任何其他物品，導致大量空間被浪費。

#### 4.3.6 正確性證明（Exchange Argument 概略）

假設最優解 O 沒有按照 v/w 排序的順序來取。那麼存在兩個物品 i, j，使得 vᵢ/wᵢ > vⱼ/wⱼ，但 O 中 j 的取用比例 > 0 而 i 的取用比例 < 1。

把 j 少取一點（減少 δ 重量），把 i 多取一點（增加 δ 重量）：
- 價值變化 = δ × (vᵢ/wᵢ - vⱼ/wⱼ) > 0

矛盾！O 不是最優的。所以最優解一定按 v/w 排序取用。QED

---

### 4.4 找零問題（Coin Change - Greedy Version）

#### 4.4.1 問題定義

用最少的硬幣湊出金額 M。硬幣面額為 d₁ > d₂ > ... > dₖ。

#### 4.4.2 Greedy 策略

每次盡量用最大面額的硬幣。

#### 4.4.3 虛擬碼

```
GREEDY-COIN-CHANGE(d, M):
    // d[1..k]: 硬幣面額（降序）, M: 目標金額
    coins ← []
    remaining ← M

    for i ← 1 to k:
        count ← ⌊remaining / d[i]⌋
        remaining ← remaining - count × d[i]
        加 count 個 d[i] 到 coins

    if remaining > 0:
        return "無法找零"
    return coins
```

#### 4.4.4 計算範例（美元系統：25, 10, 5, 1）

```
找零 M = 41 cents
面額: [25, 10, 5, 1]

Step 1: 25 cent: ⌊41/25⌋ = 1, remaining = 41 - 25 = 16
Step 2: 10 cent: ⌊16/10⌋ = 1, remaining = 16 - 10 = 6
Step 3: 5 cent:  ⌊6/5⌋ = 1,  remaining = 6 - 5 = 1
Step 4: 1 cent:  ⌊1/1⌋ = 1,  remaining = 1 - 1 = 0

結果: 25 + 10 + 5 + 1 = 41, 共 4 枚硬幣 ✓
```

#### 4.4.5 什麼幣值系統 Greedy 最優？

**Greedy 有效的系統**：
- 美元系統 {1, 5, 10, 25}：可以證明 Greedy 最優
- 任何「canonical coin system」
- 冪次系統 {1, c, c², c³, ...}（例如 {1, 2, 4, 8, ...}）

**判斷方法**：如果面額系統中，每個較大的面額都是較小面額的整數倍，那 Greedy 通常有效。但這只是充分條件，不是必要條件。

**嚴格判斷**：可以驗證所有小於最大面額的金額，Greedy 是否都給出最優解。如果都是，那對所有金額都是最優的（Pearson, 2005）。

#### 4.4.6 反例：Greedy 失敗的幣值系統

**面額 {1, 3, 4}，找零 M = 6**

```
Greedy: 4 + 1 + 1 = 6, 共 3 枚
最優解: 3 + 3 = 6, 共 2 枚

Greedy 失敗！
```

**面額 {1, 6, 10}，找零 M = 12**

```
Greedy: 10 + 1 + 1 = 12, 共 3 枚
最優解: 6 + 6 = 12, 共 2 枚

Greedy 又失敗了！
```

**結論**：找零問題的 Greedy 策略不是對所有幣值系統都有效。如果面額系統不保證 Greedy 有效，就需要用 DP。

---

### 4.5 Gas Station Problem（加油站問題）

#### 4.5.1 問題定義

你要從起點開到終點（距離 D），沿途有 n 個加油站，第 i 個加油站距離起點 dᵢ（0 = d₀ < d₁ < d₂ < ... < dₙ < dₙ₊₁ = D）。你的油箱滿時可以跑 L 公里。初始油箱是滿的。目標是**用最少的停靠次數**到達終點。

（注意：假設每次加油都加滿。）

#### 4.5.2 Greedy 策略

**盡量不停**：每次都盡量開到不能再開為止（快沒油了），然後在最後一個能到達的加油站停下加油。

等價的說法：在每個加油站，如果剩餘的油可以到達下一個加油站（或終點），就不停；否則就加油。

#### 4.5.3 虛擬碼

```
GAS-STATION(d, L, n):
    // d[0..n+1]: 各點距離起點的距離, d[0]=0, d[n+1]=D
    // L: 油箱滿時可跑的距離

    // 先檢查可行性
    for i ← 0 to n:
        if d[i+1] - d[i] > L:
            return "不可能到達"

    stops ← []
    current_fuel ← L        // 初始滿油

    for i ← 1 to n:         // 考慮每個加油站
        if current_fuel < d[i+1] - d[i]:
            // 如果不加油，到不了下一站
            // 但是...我們應該在「之前最遠能到的站」加油
            // 簡化版：遍歷時，如果到目前這站的油不夠到下一站，就在這站加油
            stops.append(i)
            current_fuel ← L
        current_fuel ← current_fuel - (d[i+1] - d[i])

    // 更精確的版本：
    // 在 i 站時，current_fuel 是到達 i 站後剩餘的油
    // 如果 current_fuel 不夠到 i+1 站，就在 i 站加油

    return stops
```

更清晰的版本：

```
GAS-STATION-CLEAR(d, L, n):
    stops ← []
    fuel_left ← L                    // 出發時滿油

    for i ← 0 to n:                  // 從起點（站0）到最後一個加油站（站n）
        fuel_left ← fuel_left - (d[i+1] - d[i])  // 假設開到下一站

        if fuel_left < 0:
            // 油不夠到下一站 → 先在站 i 加油
            // 但要確認站 i 能到站 i+1
            // （已在前面檢查過）
            // 實際上應該往前找最後能到的站加油
            // 簡化：在當前站加油
            stops.append(i)
            fuel_left ← L - (d[i+1] - d[i])

    return stops
```

**更直觀的實作**：

```
GAS-STATION-SIMPLE(d, L, n):
    stops ← []
    last_stop ← 0              // 上次加油的位置（起點）

    for i ← 1 to n + 1:        // 考慮每個點（包含終點）
        if d[i] - d[last_stop] > L:
            // 從上次加油處到點 i 超過油箱範圍
            // 必須在前一個加油站 (i-1) 加油
            if i - 1 == last_stop:
                return "不可能"   // 相鄰站距離 > L
            stops.append(i - 1)
            last_stop ← i - 1
            // 再檢查從新的 last_stop 能否到 i
            if d[i] - d[last_stop] > L:
                return "不可能"

    return stops
```

#### 4.5.4 計算範例

```
D = 25, L = 10（油箱跑 10 公里）
加油站位置: d = [0, 3, 6, 12, 16, 22, 25]
                起點 S1  S2  S3   S4   S5  終點

Step 1: 出發（在位置 0），滿油可跑 10
        能到 S1(3)? 3 ≤ 10 ✓
        能到 S2(6)? 6 ≤ 10 ✓
        能到 S3(12)? 12 > 10 ✗
        → 在 S2(位置6) 加油，stops = [S2]

Step 2: 從 S2(位置6) 出發，滿油可跑到位置 16
        能到 S3(12)? 12-6=6 ≤ 10 ✓
        能到 S4(16)? 16-6=10 ≤ 10 ✓
        能到 S5(22)? 22-6=16 > 10 ✗
        → 在 S4(位置16) 加油，stops = [S2, S4]

Step 3: 從 S4(位置16) 出發，滿油可跑到位置 26
        能到 S5(22)? 22-16=6 ≤ 10 ✓
        能到終點(25)? 25-16=9 ≤ 10 ✓
        → 直接到終點，不需再加油

結果: 停靠 [S2, S4]，共加油 2 次
```

#### 4.5.5 正確性證明（Exchange Argument 概略）

令 G = {g₁, g₂, ...} 為 Greedy 停靠的站（依序），O = {o₁, o₂, ...} 為最優解。

**Claim**：對所有 i，gᵢ ≥ oᵢ（Greedy 的第 i 次停靠不會比 OPT 早）。

**歸納證明**：
- Base: g₁ ≥ o₁（Greedy 盡量不停，所以第一次停的位置最遠）
- Inductive: 假設 gᵢ ≥ oᵢ。從 gᵢ 出發，Greedy 盡量開到最遠才停，所以 gᵢ₊₁ ≥ oᵢ₊₁。

因為 Greedy 每次都停得比 OPT 晚（或一樣），所以 Greedy 的停靠次數 ≤ OPT 的停靠次數。QED

---

### 4.6 Stable Matching（穩定匹配）—— Gale-Shapley 演算法簡介

#### 4.6.1 問題定義

有 n 個男生和 n 個女生，每個人對異性都有一個完整的偏好排名。目標是找一個穩定的完美匹配。

**穩定**的意思是：不存在一對 (m, w) 使得 m 和 w 都更偏好對方而不是各自目前的配對對象。如果存在這樣的 (m, w)，稱為「blocking pair」，匹配就不穩定。

#### 4.6.2 Gale-Shapley 演算法

```
GALE-SHAPLEY(Men, Women):
    // 每個人都有一個偏好列表
    所有人都設為「未配對」

    while 存在未配對的男生 m:
        w ← m 的偏好列表中，他還沒有求過婚的最高排名女生
        if w 未配對:
            配對 (m, w)
        else:   // w 已與某個 m' 配對
            if w 比較偏好 m（勝過 m'）:
                配對 (m, w)         // m' 變成未配對
            else:
                m 被拒絕，繼續下一輪

    return 所有配對
```

#### 4.6.3 重要性質

1. **一定會終止**：每個男生最多向每個女生求婚一次，所以最多 n² 輪
2. **結果是完美匹配**：每個人都會被配對
3. **結果是穩定的**：不存在 blocking pair
4. **男方最優**：在所有穩定匹配中，每個男生都得到他能得到的最好結果
5. **女方最劣**：在所有穩定匹配中，每個女生都得到她能得到的最差結果

**時間複雜度**：O(n²)

#### 4.6.4 為什麼是 Greedy？

Gale-Shapley 是 Greedy 的一種體現：每個男生在每一步都向自己最喜歡的（還沒被拒絕的）女生求婚。這是一種局部最佳的策略。

#### 4.6.5 簡短範例

```
男生偏好:           女生偏好:
m1: w1 > w2 > w3    w1: m2 > m1 > m3
m2: w1 > w2 > w3    w2: m1 > m2 > m3
m3: w1 > w2 > w3    w3: m1 > m2 > m3

Round 1: m1→w1(接受), m2→w1(w1比較喜歡m2,踢掉m1), m3→w1(被拒)
  配對: (m2,w1), m1 和 m3 未配對

Round 2: m1→w2(接受), m3→w2(w2比較喜歡m1,拒絕m3)
  配對: (m2,w1), (m1,w2), m3 未配對

Round 3: m3→w3(接受)
  配對: (m2,w1), (m1,w2), (m3,w3)

最終穩定匹配: {(m1,w2), (m2,w1), (m3,w3)}
```

---

## 5. Greedy 失敗的經典反例

這些問題看起來很像可以用 Greedy，但其實不行。認識它們可以幫你在考試時避免陷阱。

### 5.1 0/1 Knapsack

如前所述（4.3.5 節），按 v/w 排序的 Greedy 策略對 0/1 Knapsack 無效。

**直覺原因**：不能分割物品 → 可能浪費背包空間 → 局部最優不等於全域最優。

**反例**：

```
物品:     A      B      C
重量 w:   30     20     20
價值 v:   150    100    90
v/w:      5      5      4.5

背包容量 W = 40

Greedy（按v/w）: 選 A(w=30, v=150), 剩餘 10, B 和 C 都放不下
                 總價值 = 150

最優解: 選 B + C (w=20+20=40, v=100+90=190)
        總價值 = 190

差了 40！
```

### 5.2 Longest Path（一般圖）

在一般圖（甚至 DAG）中找最長路徑，Greedy 策略（每步走到權重最大的鄰居）不一定對。

```
反例：
    A --5-- B --1-- D
    |              |
    2              100
    |              |
    C ----1---- (直接到D)

從 A 到 D:
Greedy: A → B (權重5) → D (權重1)，總長 = 6
最優: A → C (權重2) → D (權重100)，總長 = 102
```

注意：最長路徑問題在一般圖上是 NP-hard 的！（但在 DAG 上可以用 DP 在多項式時間解決）

### 5.3 TSP（旅行商問題）

**最近鄰居 Greedy**：每次走到最近的未訪問城市。

```
反例：
城市:  A(0,0), B(1,0), C(2,0), D(1,1)

距離:
  A-B: 1,  A-C: 2,  A-D: √2 ≈ 1.41
  B-C: 1,  B-D: 1
  C-D: √2 ≈ 1.41

從 A 出發的 Greedy:
A → B(距離1) → C(距離1) → D(距離1.41) → A(距離1.41)
總長 = 1 + 1 + 1.41 + 1.41 = 4.82

最優解:
A → B(1) → D(1) → C(1.41) → A(2)  = 5.41
或 A → D(1.41) → B(1) → C(1) → A(2) = 5.41
或 A → B(1) → C(1) → D(1.41) → A(1.41) = 4.82 (這個例子可能不夠好)

更好的反例——四個城市形成長方形：
A(0,0), B(10,0), C(10,1), D(0,1)

Greedy from A: A→D(1)→C(10.05)→B(1)→A(10) = 22.05
最優: A→B(10)→C(1)→D(10)→A(1) = 22

好，讓我用一個更明顯的反例：
5 個城市在一條線上但有捷徑

城市在座標: A(0), B(1), C(5), D(6), E(10)
從 A 開始:
Greedy: A→B(1)→C(4)→D(1)→E(4)→A(10) = 20
最優:   A→B(1)→D(5)→C(1)→E(5)→A(10) = 22 (更差)
        A→E(10)→D(4)→C(1)→B(4)→A(1) = 20 (一樣)
```

TSP 的重點不在於找一個特定反例，而在於：**TSP 是 NP-hard 的，所以不可能有多項式時間的最優演算法（除非 P = NP）**。Greedy 最近鄰居法只是一個近似演算法。

### 5.4 共同特徵

這些 Greedy 失敗的問題有什麼共通點？

- **沒有 Greedy Choice Property**：局部最佳選擇可能把你引向全域次優解
- **選擇之間有複雜的相互依賴**：選了一個會影響後面所有的選擇空間
- **沒有辦法「交換」**：你不能簡單地把 OPT 中的元素換成 Greedy 的元素而不影響可行性

---

## 6. 看起來像 Greedy 但其實要用 DP 的判斷指南

### 6.1 快速判斷流程

```
問題來了
  │
  ▼
每一步的選擇是否只需要看「當前狀態」？
  │                    │
  是                   否
  │                    │
  ▼                    ▼
做了選擇後，是否         這需要考慮多個
只剩一個子問題？         子問題的結果 → DP
  │          │
  是         否 → DP
  │
  ▼
能否證明局部最優
選擇一定在某個
全域最優解中？
  │          │
  是         否 → DP
  │
  ▼
Greedy 可能適用！
（還是要嚴格證明）
```

### 6.2 具體指標

| 信號 | 可能是 Greedy | 可能是 DP |
|------|--------------|-----------|
| 排序後一次掃描就能解 | ✓ | |
| 需要「選或不選」的二元決策 | | ✓ |
| 有明確的「最佳局部選擇」 | ✓ | |
| 問「方法數」或「所有最優解」 | | ✓ |
| 子問題之間有重疊 | | ✓ |
| 選擇不影響後面的可選範圍 | ✓ | |
| 選擇會大幅改變後面的狀態空間 | | ✓ |

### 6.3 經典易混淆問題

| 問題 | 看起來像 | 實際上 | 原因 |
|------|---------|--------|------|
| Activity Selection | Greedy | **Greedy** | 有 Greedy Choice Property |
| Weighted Job Scheduling | Greedy | **DP** | 權重不同，不能只看結束時間 |
| 0/1 Knapsack | Greedy | **DP** | 不能分割，局部最優不保全域 |
| Fractional Knapsack | Greedy | **Greedy** | 可以分割，不浪費空間 |
| LIS (最長遞增子序列) | Greedy | **DP** (或 Greedy+Binary Search) | 純 Greedy 不行，但加上巧妙的資料結構可以 |
| Coin Change (一般面額) | Greedy | **DP** | 面額間的整除關係不成立 |
| Coin Change (標準面額) | Greedy | **Greedy** | 面額間有良好的整除關係 |
| Matrix Chain | Greedy | **DP** | 區間 DP，Greedy 找不到正確分割點 |

### 6.4 黃金法則

> **如果你想不到怎麼證明 Greedy 正確，它大概就不是 Greedy 問題。**
>
> **如果你能快速想到一個反例推翻某個 Greedy 策略，那幾乎確定需要 DP。**

---

## 7. Matroid 簡介 (Bonus)

### 7.1 動機

你有沒有想過，為什麼某些 Greedy 有效（像 Kruskal 的最小生成樹），而某些不行？有沒有一個統一的理論框架可以判斷？

答案是有的，就是 **Matroid（擬陣）**。

### 7.2 定義

一個 **Matroid** M = (S, I) 包含：
- S：一個有限集合（ground set）
- I：S 的子集合的族（family of subsets），稱為「獨立集」

滿足以下三個公理：

1. **空集獨立**：∅ ∈ I
2. **遺傳性（Hereditary Property）**：如果 B ∈ I 且 A ⊆ B，則 A ∈ I
   （獨立集的子集也是獨立的）
3. **交換性（Exchange/Augmentation Property）**：如果 A, B ∈ I 且 |A| < |B|，則存在 x ∈ B \ A 使得 A ∪ {x} ∈ I
   （較小的獨立集可以從較大的獨立集借一個元素來擴充）

### 7.3 例子

**圖 Matroid（Graphic Matroid）**：
- S = 圖 G 的所有邊
- I = 不形成環的邊集合（即森林的邊集）
- 驗證三個公理：
  1. 空集（沒有邊）是森林 ✓
  2. 森林的子集還是森林 ✓
  3. 較小的森林可以從較大的森林借一條邊而不形成環 ✓（因為較大的森林連通更多頂點）

**均勻 Matroid（Uniform Matroid）**：
- S = n 個元素
- I = 所有大小 ≤ k 的子集
- 這就是「從 n 個裡面最多選 k 個」的問題

### 7.4 Matroid 上的 Greedy 演算法

**定理（Matroid Greedy Theorem）**：

對一個 Matroid M = (S, I) 和權重函數 w: S → R⁺，以下 Greedy 演算法一定能找到最大權重的獨立集（maximal independent set of maximum weight）：

```
MATROID-GREEDY(S, I, w):
    按 w 降序排序 S 中的元素
    A ← ∅
    for each x in S (按 w 降序):
        if A ∪ {x} ∈ I:       // 如果加入 x 後仍獨立
            A ← A ∪ {x}
    return A
```

**反過來也成立**：如果對所有非負權重函數，上面的 Greedy 都能得到最優解，那麼 (S, I) 就是一個 Matroid。

### 7.5 為什麼這很重要？

| 問題 | 是否為 Matroid？ | Greedy 有效？ |
|------|-----------------|--------------|
| 最小生成樹 (Kruskal) | 是（Graphic Matroid） | ✓ |
| 最大權重森林 | 是（Graphic Matroid） | ✓ |
| 0/1 Knapsack | 否（不滿足交換性） | ✗ |
| Activity Selection | 不直接是 Matroid，但有類似結構 | ✓ |
| 任務排程（截止日期 + 懲罰） | 是（排程 Matroid） | ✓ |

### 7.6 Matroid 的直覺

Matroid 捕捉了一種「獨立性」的概念，就像線性代數中向量的線性獨立一樣。事實上，Matroid 的名字就來自 "matrix"。

當一個問題可以被建模成 Matroid 上的最優化問題時，Greedy 就一定有效。所以如果你能證明一個問題有 Matroid 結構，你就自動證明了 Greedy 的正確性——不需要另外做 Exchange Argument 或 Greedy Stays Ahead。

---

## 常見陷阱

### 陷阱 1：直覺上「顯然」的 Greedy 策略可能是錯的

Activity Selection 有 4 種直覺策略（最早開始、最短、最少衝突、最早結束），只有一種是對的。**永遠先想反例！**

### 陷阱 2：忘了證明正確性

考試中光是「描述 Greedy 策略」通常拿不到滿分。你需要嚴格證明，最常用的就是 Exchange Argument 或 Greedy Stays Ahead。

### 陷阱 3：把 Greedy 用在不適合的問題上

0/1 Knapsack、一般找零問題、Weighted Job Scheduling 等等，長得很像 Greedy 但不是。養成「先找反例」的習慣。

### 陷阱 4：Exchange Argument 的交換沒有保持可行性

做交換時，一定要驗證新的解仍然是 feasible 的。很多同學只證了「不會變差」但忘了證「仍然可行」。

### 陷阱 5：Greedy Stays Ahead 的度量定義不好

「Stays Ahead」需要一個好的度量。如果度量定義得不好，歸納步驟會卡住。常見的好度量：
- Activity Selection：結束時間
- Job Scheduling：完成的工作數量
- Gas Station：走過的距離

### 陷阱 6：Ternary Huffman 忘了補虛擬字元

k-ary Huffman 需要 (n-1) mod (k-1) = 0，否則最後一層不滿。忘了補虛擬字元會得到非最優的樹。

### 陷阱 7：混淆 Greedy 和 DP 的適用條件

Optimal Substructure 兩者都需要，差異在於 Greedy Choice Property。只有 Greedy 需要這個，DP 不需要（DP 是嘗試所有子問題再選最好的）。

---

## 小結

| 主題 | 關鍵重點 |
|------|---------|
| Greedy 框架 | 每步做局部最佳選擇，不回溯 |
| 必要條件 | Greedy Choice Property + Optimal Substructure |
| 證明方法 | Exchange Argument 或 Greedy Stays Ahead |
| Activity Selection | 選最早結束，其他三種策略都有反例 |
| Huffman Coding | 每次合併頻率最低的兩個（或 k 個） |
| Fractional Knapsack | 按 v/w 排序，可以切所以有效 |
| 找零問題 | 只在特定幣值系統有效 |
| Gas Station | 盡量不停，用 Greedy Stays Ahead 證明 |
| Stable Matching | Gale-Shapley，O(n²)，男方最優 |
| Greedy 失敗 | 0/1 Knapsack, Longest Path, TSP |
| Matroid | 統一的理論框架，Matroid 上 Greedy 一定有效 |

---

## 自我檢測題

### 觀念題

1. **Greedy vs DP**：用自己的話解釋 Greedy 和 DP 的核心差別。什麼時候該用 Greedy？什麼時候該用 DP？

2. **為什麼 Greedy 有時候錯？** 用 0/1 背包問題舉一個具體的反例，說明「每步選 CP 值最高的」不一定最好。

3. **兩種證明方法的差異**：Exchange Argument 和 Greedy Stays Ahead 分別適合什麼情況？

### 計算題

4. **Activity Selection**：以下 6 個活動，用貪心（選最早結束的）找出最大相容活動集合。
   | 活動 | 開始 | 結束 |
   |------|------|------|
   | P | 0 | 3 |
   | Q | 1 | 4 |
   | R | 3 | 5 |
   | S | 4 | 7 |
   | T | 5 | 9 |
   | U | 8 | 10 |

5. **Huffman Coding**：字元頻率為 {A:3, B:5, C:8, D:12, E:15}，畫出完整的 Huffman Tree 建構過程，並寫出每個字元的編碼。

6. **Fractional Knapsack**：物品如下，背包容量 W = 15。用 Greedy 求最大價值。
   | 物品 | 重量 | 價值 | CP 值 |
   |------|------|------|-------|
   | A | 5 | 30 | 6 |
   | B | 10 | 40 | 4 |
   | C | 8 | 32 | 4 |

7. **找零反例**：面額 {1, 5, 8}，金額 10。Greedy 給出幾枚？最佳解是幾枚？

### 參考答案提示

- 第 4 題：排序後 P(0,3), Q(1,4), R(3,5), S(4,7), T(5,9), U(8,10)。選 P → R（3$\geq$3）→ U（8$\geq$5? 不行。看 S：4$\geq$5? 不行。看 T：5$\geq$5 可以）→ T → U（8$<$9 不行）。答案：{P, R, U} 或 {P, R, T} 等（需確認相容性）
- 第 5 題：先合併 A(3)+B(5)=8，再合併 8+C(8)=16，再合併 D(12)+E(15)=27，最後 16+27=43
- 第 7 題：Greedy：8+1+1=3 枚；最佳：5+5=2 枚
