# 時間空間複雜度完全指南 — Time & Space Complexity

> **適用對象**：基礎較弱、準備 Google / NVIDIA 面試的工程師
> **教學風格**：從零開始，每個觀念都有數值範例，一步步推導
> **語言**：繁體中文解說 + English technical terms
> **目標**：讀完後能在面試中自信分析任何算法的 Time / Space Complexity

---

## 第一章：什麼是 Big-O？— 用生活比喻理解

### 1.1 為什麼需要 Big-O？

你寫了一段程式，跑 10 筆資料要 0.001 秒，跑 100 筆要 0.01 秒，跑 10000 筆要 1 秒。
**問題**：如果資料量變成 100 萬筆，要跑多久？

Big-O 就是回答這個問題的工具 — 它描述**當輸入規模 n 趨近無窮大時，運行時間（或空間）的增長趨勢**。

核心觀念：
- Big-O 不在乎常數倍數：O(2n) = O(3n) = O(n)
- Big-O 只保留最高次項：O(n² + n) = O(n²)
- Big-O 描述的是**最壞情況（worst case）**的上界

```
為什麼忽略常數？

Algorithm A 跑 2n 步，B 跑 100n 步 → B 永遠慢 50 倍（常數倍差距）
但 Algorithm C 跑 n² 步：
- n = 10:    C = 100      → 還行
- n = 10^6:  C = 10^12    → 跑不完
- n = 10^9:  C = 10^18    → 完全不可能
增長趨勢才是決定生死的關鍵！
```

### 1.2 七個常見複雜度 — 生活比喻

#### O(1) — Constant Time：查字典的目錄

不管字典有 100 頁還是 10000 頁，目錄永遠在第一頁。翻開就找到，花的時間不隨字典厚度改變。

```python
def get_first(arr):
    return arr[0]  # 不管 arr 有多長，都只做一步

def get_by_index(arr, i):
    return arr[i]  # 記憶體位址直接算出來，一步到位

def hashmap_lookup(d, key):
    return d[key]  # hash 計算 + 直接跳到位址，O(1) average
```

#### O(log n) — Logarithmic Time：翻字典找字

想在字典裡找「熊」這個字。不會一頁一頁翻，而是：
1. 翻到中間 — 太前面了，往後半翻
2. 翻到 3/4 處 — 太後面了，往前翻
3. 每次砍掉一半...

```
n = 1000 頁的字典：
第 1 次翻：剩 500 頁
第 2 次翻：剩 250 頁
第 3 次翻：剩 125 頁
第 4 次翻：剩 63 頁
第 5 次翻：剩 32 頁
第 6 次翻：剩 16 頁
第 7 次翻：剩 8 頁
第 8 次翻：剩 4 頁
第 9 次翻：剩 2 頁
第 10 次翻：剩 1 頁 → 找到了！

1000 頁只需翻 10 次！因為 2^10 = 1024 ≈ 1000
```

**數學原理**：每次砍半，砍 k 次後剩 n/2^k。當 n/2^k = 1 時，k = log₂(n)。

#### O(n) — Linear Time：數人頭

教室裡有 n 個學生，要數有幾個人。唯一的方法就是一個一個數。
100 人數 100 次，1000 人數 1000 次 — 時間和人數成正比。

```python
def count_sum(arr):     # O(n)
    total = 0
    for x in arr:       # 每個元素看一次
        total += x
    return total

def find_max(arr):      # O(n)
    best = arr[0]
    for x in arr:       # 每個元素看一次
        best = max(best, x)
    return best
```

#### O(n log n) — Linearithmic Time：排撲克牌（Merge Sort）

想像你有 n 張撲克牌要排序：
1. 把牌分成兩堆（分）
2. 每堆各自排好（遞迴）
3. 兩堆合併成一堆（合）

分的層數 = log n，每層合併要看 n 張牌 → n x log n。

```
8 張牌的 Merge Sort：

層數 0：[8,3,5,1,7,2,6,4]                    ← 合併：比較 8 次
層數 1：[8,3,5,1]  [7,2,6,4]                  ← 合併：各比較 4 次 = 8 次
層數 2：[8,3] [5,1] [7,2] [6,4]               ← 合併：各比較 2 次 = 8 次
層數 3：[8][3] [5][1] [7][2] [6][4]           ← 不用比較（只有一張）

總共 log₂(8) = 3 層，每層做 n = 8 次比較
Total = 8 × 3 = 24 = O(n log n)
```

#### O(n²) — Quadratic Time：握手問題

派對上有 n 個人，每個人要跟其他每個人握一次手。

```
n = 5 人（A, B, C, D, E）：
A 握 4 次，B 握 3 次，C 握 2 次，D 握 1 次，E 握 0 次
總共 = 4+3+2+1+0 = 10 = n(n-1)/2 = 5×4/2 = 10 → O(n²)
```

#### O(2^n) — Exponential Time：密碼暴力破解

密碼每一位有 2 種選擇（0 或 1）。每多一位，可能性翻一倍。

```
1 位：2 種 → 2 位：4 種 → 3 位：8 種 → n 位：2^n 種

n = 20: 2^20 = 1,048,576（一百萬，還行）
n = 30: 2^30 = 1,073,741,824（十億，很慢）
n = 40: 2^40 ≈ 10^12（一兆，跑不完）
```

#### O(n!) — Factorial Time：排列所有可能

n 個人排隊，第一個位置有 n 個人選，第二個位置有 n-1 個人選...

```
3 個人排列 = 3! = 6 種，5! = 120，10! = 3,628,800
15! ≈ 1.3×10^12（一兆，跑不完），20! ≈ 2.4×10^18（宇宙等級）
```

### 1.3 數值對照表 — 直觀感受增長速度

```
假設電腦每秒執行 10^8 次操作：

┌──────┬──────┬─────────┬──────┬──────────┬──────────┬──────────┬──────────┐
│  n   │ O(1) │ O(logn) │ O(n) │ O(nlogn) │  O(n²)   │  O(2^n)  │  O(n!)   │
├──────┼──────┼─────────┼──────┼──────────┼──────────┼──────────┼──────────┤
│   10 │    1 │       3 │   10 │       33 │      100 │    1,024 │  3.6×10⁶ │
│  100 │    1 │       7 │  100 │      664 │   10,000 │  10³⁰    │    ∞     │
│ 1000 │    1 │      10 │ 1000 │    9,966 │  10⁶     │    ∞     │    ∞     │
│  10⁴ │    1 │      13 │  10⁴ │  1.3×10⁵ │  10⁸     │    ∞     │    ∞     │
│  10⁵ │    1 │      17 │  10⁵ │  1.7×10⁶ │  10¹⁰    │    ∞     │    ∞     │
│  10⁶ │    1 │      20 │  10⁶ │  2×10⁷   │  10¹²    │    ∞     │    ∞     │
└──────┴──────┴─────────┴──────┴──────────┴──────────┴──────────┴──────────┘

∞ 表示「宇宙毀滅都跑不完」
10⁸ 次操作 ≈ 1 秒（面試時限），10⁹ 以上 = TLE
```

### 1.4 面試黃金法則 — 從 n 的範圍推算可接受的複雜度

```
這是 LeetCode / 面試最實用的速查表：

┌────────────────┬────────────────────────┬───────────────────────┐
│  n 的範圍       │  可接受的複雜度          │  通常對應的算法         │
├────────────────┼────────────────────────┼───────────────────────┤
│ n ≤ 10         │ O(n!) 或 O(n × 2^n)    │ Backtracking 暴力全搜  │
│ n ≤ 20         │ O(2^n)                 │ Bitmask DP、暴力枚舉   │
│ n ≤ 500        │ O(n³)                  │ 三重迴圈、Floyd-Warshall│
│ n ≤ 5000       │ O(n²)                  │ Bubble Sort、2D DP     │
│ n ≤ 10⁵        │ O(n log n)             │ Sorting、Heap、Segment │
│ n ≤ 10⁶        │ O(n)                   │ HashMap、Two Pointers  │
│ n ≤ 10¹⁸       │ O(log n) 或 O(1)       │ Binary Search、數學公式│
└────────────────┴────────────────────────┴───────────────────────┘

面試時看到 n ≤ 10^5，立刻知道需要 O(n log n) 或更好的算法！
```

---

## 第二章：如何分析迴圈的複雜度

### 2.1 單層迴圈 — O(n)

```python
# 範例 1：遍歷一次
def find_sum(arr):
    total = 0              # O(1)
    for x in arr:          # 執行 n 次
        total += x         # O(1)
    return total           # O(1)
# Total: O(1) + n × O(1) + O(1) = O(n)

# 範例 2：遍歷固定比例
def check_first_half(arr):
    n = len(arr)
    for i in range(n // 2):  # 執行 n/2 次
        print(arr[i])
# Total: O(n/2) = O(n)  ← 常數倍數不影響

# 範例 3：跳著遍歷
def check_every_third(arr):
    n = len(arr)
    for i in range(0, n, 3):  # 執行 n/3 次
        print(arr[i])
# Total: O(n/3) = O(n)  ← 還是 O(n)
```

### 2.2 巢狀迴圈 — O(n²)

```python
# 範例 4：標準雙層迴圈
def print_pairs(arr):
    n = len(arr)
    for i in range(n):        # 外層 n 次
        for j in range(n):    # 內層 n 次
            print(arr[i], arr[j])
# Total: n × n = O(n²)

# 範例 5：三角形迴圈（上三角）
def print_unique_pairs(arr):
    n = len(arr)
    for i in range(n):            # n 次
        for j in range(i+1, n):   # 第一次 n-1 次，第二次 n-2 次...
            print(arr[i], arr[j])
# 計算：
# i=0: j 跑 n-1 次
# i=1: j 跑 n-2 次
# ...
# i=n-2: j 跑 1 次
# i=n-1: j 跑 0 次
# Total = (n-1) + (n-2) + ... + 1 + 0 = n(n-1)/2 = O(n²)
```

### 2.3 不等長巢狀迴圈 — O(n * m)

```python
# 範例 6：兩個不同長度的陣列
def compare_all(arr1, arr2):
    for x in arr1:           # n 次（n = len(arr1)）
        for y in arr2:       # m 次（m = len(arr2)）
            if x == y:
                print("match")
# Total: O(n × m)
# 注意：這不是 O(n²)！除非 n = m

# 範例 7：矩陣遍歷
def traverse_matrix(matrix):
    rows = len(matrix)           # rows
    cols = len(matrix[0])        # cols
    for i in range(rows):        # rows 次
        for j in range(cols):    # cols 次
            print(matrix[i][j])
# Total: O(rows × cols)
```

### 2.4 迴圈減半 — O(log n)

```python
# 範例 8：每次除以 2
def halving(n):
    i = n
    count = 0
    while i > 0:
        i //= 2
        count += 1
    return count
# 追蹤 n = 32：
# i: 32 → 16 → 8 → 4 → 2 → 1 → 0
# count: 1   2    3   4   5   6
# 執行 6 次，因為 log₂(32) = 5（加上最後一次 1→0）≈ O(log n)

# 範例 9：每次乘以 2
def doubling(n):
    i = 1
    count = 0
    while i < n:
        i *= 2
        count += 1
    return count
# 追蹤 n = 100：
# i: 1 → 2 → 4 → 8 → 16 → 32 → 64 → 128（>100, 停止）
# count: 1  2   3   4    5    6    7
# 執行 7 次 = ⌈log₂(100)⌉ = O(log n)

# 範例 10：每次除以 3（n=81: 81→27→9→3→1→0, 共 5 次 = O(log n)）
# 注意：O(log₃n) = O(log₂n / log₂3) = O(log n)，底數不影響 Big-O！
```

### 2.5 迴圈套減半 — O(n log n)

```python
# 範例 11：外層線性 × 內層對數
def example_nlogn(n):
    for i in range(n):       # n 次
        j = n
        while j > 0:        # log n 次
            j //= 2
# Total: n × log n = O(n log n)

# 範例 12：外層對數 × 內層線性
def example_nlogn_v2(arr):
    n = len(arr)
    gap = n
    while gap > 0:           # log n 次
        for i in range(n):   # n 次
            pass  # do something
        gap //= 2
# Total: log n × n = O(n log n)
```

### 2.6 兩個獨立迴圈 — 相加

```python
# 範例 13：先 O(n) 再 O(n)
def two_passes(arr):
    n = len(arr)
    # Pass 1: 找最大值
    max_val = arr[0]
    for x in arr:           # O(n)
        max_val = max(max_val, x)

    # Pass 2: 計算離最大值的距離
    for x in arr:           # O(n)
        print(max_val - x)
# Total: O(n) + O(n) = O(2n) = O(n)  ← 相加取最大

# 範例 14：先 O(n) 再 O(n²)
def mixed(arr):
    n = len(arr)
    for x in arr:           # O(n)
        print(x)
    for i in range(n):      # O(n²)
        for j in range(n):
            print(i, j)
# Total: O(n) + O(n²) = O(n²)  ← 低次項被吃掉
```

### 2.7 實戰分析：Two Sum

```python
# 解法 1：Brute Force — O(n²)
def twoSum_brute(nums, target):
    n = len(nums)
    for i in range(n):                 # n 次
        for j in range(i + 1, n):      # 平均 n/2 次
            if nums[i] + nums[j] == target:
                return [i, j]
# 分析：
# i=0: 內層跑 n-1 次
# i=1: 內層跑 n-2 次
# ...
# Total = (n-1)+(n-2)+...+1 = n(n-1)/2 = O(n²)

# 解法 2：HashMap — O(n)
def twoSum_hash(nums, target):
    seen = {}                          # 空間 O(n)
    for i, num in enumerate(nums):     # n 次
        complement = target - num      # O(1)
        if complement in seen:         # O(1) average
            return [seen[complement], i]
        seen[num] = i                  # O(1)
# 分析：
# 迴圈跑 n 次，每次內部操作都是 O(1)
# Total Time: O(n)
# Total Space: O(n)（HashMap 最多存 n 個元素）

# 數值比較（n = 10000）：
# Brute Force: 10000 × 9999 / 2 = 49,995,000 次操作
# HashMap:     10000 次操作
# 快了 5000 倍！
```

### 2.8 實戰分析：更多迴圈模式

```python
# 範例 15：迴圈的上界依賴外層 — 仔細算！
def example_tricky(n):
    for i in range(n):
        for j in range(i):  # j 從 0 到 i-1
            print(i, j)
# i=0: 0 次
# i=1: 1 次
# i=2: 2 次
# ...
# i=n-1: n-1 次
# Total = 0+1+2+...+(n-1) = n(n-1)/2 = O(n²)

# 範例 16：看起來像 O(n²) 但其實是 O(n)
def example_amortized(arr):
    n = len(arr)
    j = 0
    for i in range(n):       # n 次
        while j < n and arr[j] < arr[i]:
            j += 1           # j 最多從 0 走到 n
# 關鍵：j 只會增加，永遠不會重置！
# 外層跑 n 次，但 j 總共只從 0 走到 n
# Total = n (外層) + n (j 的移動) = O(2n) = O(n)

# 範例 17：String 操作隱藏的複雜度
def concat_strings(n):
    s = ""
    for i in range(n):
        s += "a"    # 字串不可變！每次都要複製整個字串
# i=0: 複製 1 個字元
# i=1: 複製 2 個字元
# ...
# i=n-1: 複製 n 個字元
# Total = 1+2+...+n = n(n+1)/2 = O(n²)  ← 陷阱！
# 修正方式：用 list 收集再 join → O(n)
```

---

## 第三章：如何分析遞迴的複雜度

### 3.1 遞迴的基本分析 — 數呼叫次數

```python
# 範例 18：簡單線性遞迴
def factorial(n):
    if n <= 1:          # base case
        return 1
    return n * factorial(n - 1)  # 呼叫 1 次，n-1

# 呼叫鏈：factorial(5) → factorial(4) → factorial(3) → factorial(2) → factorial(1)
# 總共呼叫 n 次，每次做 O(1) → Total: O(n)
# 空間：call stack 深度 = n → O(n)

# 範例 19：每次砍半的遞迴
def binary_search_recursive(arr, target, lo, hi):
    if lo > hi:
        return -1
    mid = (lo + hi) // 2
    if arr[mid] == target:
        return mid
    elif arr[mid] < target:
        return binary_search_recursive(arr, target, mid + 1, hi)
    else:
        return binary_search_recursive(arr, target, lo, mid - 1)

# 每次呼叫只產生 1 個子問題，問題規模砍半
# 呼叫鏈深度 = log n，每次做 O(1)
# Total Time: O(log n)
# Total Space: O(log n)（call stack）
```

### 3.2 遞迴樹方法 — Fibonacci 完整推導

```python
# 範例 20：Fibonacci（無 memo）
def fib(n):
    if n <= 1:
        return n
    return fib(n-1) + fib(n-2)
```

畫出 fib(5) 的遞迴樹：

```
                    fib(5)
                  /        \
             fib(4)        fib(3)
            /      \       /     \
        fib(3)   fib(2)  fib(2)  fib(1)
        /   \    /    \   /   \
    fib(2) fib(1) fib(1) fib(0) fib(1) fib(0)
    /   \
fib(1) fib(0)

數一下節點數：15 個
```

每個節點做 O(1) 工作，樹高 = n，每層最多 2 倍節點
總節點 ≤ 2^0 + 2^1 + ... + 2^n = 2^(n+1) - 1 → **Time = O(2^n)，Space = O(n)**

```python
# 範例 21：Fibonacci（有 memo）
def fib_memo(n, memo={}):
    if n in memo:
        return memo[n]
    if n <= 1:
        return n
    memo[n] = fib_memo(n-1, memo) + fib_memo(n-2, memo)
    return memo[n]
```

```
Memoized fib(5) 的實際執行：

fib(5) → 需要 fib(4) 和 fib(3)
  fib(4) → 需要 fib(3) 和 fib(2)
    fib(3) → 需要 fib(2) 和 fib(1)
      fib(2) → 需要 fib(1) 和 fib(0)
        fib(1) → return 1    ← base case
        fib(0) → return 0    ← base case
      fib(2) = 1             ← 存入 memo
      fib(1) → return 1      ← base case
    fib(3) = 2               ← 存入 memo
    fib(2) → memo hit!        ← O(1) 直接查表
  fib(4) = 3                 ← 存入 memo
  fib(3) → memo hit!          ← O(1) 直接查表
fib(5) = 5

每個 fib(k) 只算一次，共 n 個值
Total Time: O(n)
Total Space: O(n)（memo + call stack）
```

**2^n vs n 的差距**：
| n | O(2^n) 次操作 | O(n) 次操作 | 加速倍數 |
|---|---|---|---|
| 10 | 1,024 | 10 | 102x |
| 20 | 1,048,576 | 20 | 52,429x |
| 30 | 1,073,741,824 | 30 | 35,791,394x |
| 50 | 1.1 x 10^15 | 50 | 2.3 x 10^13x |

### 3.3 Master Theorem — 三行搞定遞迴複雜度

**適用情境**：當遞迴關係長這樣時：

```
T(n) = a × T(n/b) + O(n^d)

a = 子問題數量
b = 問題縮小倍數
d = 合併/分割的工作量指數
```

**三個 Case**（只需要比較 log_b(a) 和 d）：

```
設 c = log_b(a)

Case 1：若 c > d → T(n) = O(n^c)           ← 葉子做的事比較多
Case 2：若 c = d → T(n) = O(n^d × log n)   ← 每層一樣多
Case 3：若 c < d → T(n) = O(n^d)           ← 根做的事比較多
```

**範例推導**：

```
【Merge Sort】T(n) = 2T(n/2) + O(n)
a = 2（分成 2 個子問題）
b = 2（每個子問題大小是 n/2）
d = 1（合併要 O(n) = O(n^1)）
c = log₂(2) = 1
c = d = 1 → Case 2 → T(n) = O(n^1 × log n) = O(n log n) ✓

【Binary Search】T(n) = T(n/2) + O(1)
a = 1（只往一邊搜）
b = 2（問題砍半）
d = 0（比較是 O(1) = O(n^0)）
c = log₂(1) = 0
c = d = 0 → Case 2 → T(n) = O(n^0 × log n) = O(log n) ✓

【Strassen 矩陣乘法】T(n) = 7T(n/2) + O(n²)
a = 7, b = 2, d = 2
c = log₂(7) ≈ 2.807
c > d → Case 1 → T(n) = O(n^2.807) ≈ O(n^2.81)

【Karatsuba 大數乘法】T(n) = 3T(n/2) + O(n)
a = 3, b = 2, d = 1
c = log₂(3) ≈ 1.585
c > d → Case 1 → T(n) = O(n^1.585)

【普通遞迴遍歷 Array】T(n) = T(n-1) + O(1)
注意：Master Theorem 不適用！因為不是 T(n/b) 的形式
這種用代入法：T(n) = T(n-1) + 1 = T(n-2) + 2 = ... = T(0) + n = O(n)
```

### 3.4 DFS / BFS 的複雜度分析

```python
# 範例 22：Tree DFS — O(n) time, O(h) space
def dfs_tree(root):
    if not root: return
    dfs_tree(root.left)
    dfs_tree(root.right)
# 每個節點訪問一次 → O(n)，空間 = 樹高 h（平衡 logn，歪斜 n）

# 範例 23：Graph DFS — O(V + E) time, O(V) space
def dfs_graph(graph, start):
    visited = set()
    def dfs(node):
        visited.add(node)              # 每個節點最多加入一次 → O(V)
        for neighbor in graph[node]:   # 每條邊最多檢查一次 → O(E)
            if neighbor not in visited:
                dfs(neighbor)
    dfs(start)

# 範例 24：Grid DFS — O(rows × cols)
# 每個格子最多訪問一次，4 個方向但被 visited 擋住

# 範例 25：BFS — O(V + E) time, O(V) space
from collections import deque
def bfs(graph, start):
    visited = {start}
    queue = deque([start])
    while queue:
        node = queue.popleft()
        for neighbor in graph[node]:
            if neighbor not in visited:
                visited.add(neighbor)
                queue.append(neighbor)
```

### 3.5 Backtracking 的複雜度

```python
# 範例 26：生成所有子集 — O(n × 2^n)
# 每個元素選或不選 → 2^n 個子集，每個子集複製 O(n)
# Total Time: O(n × 2^n)，Space: O(n) 遞迴深度

# 範例 27：生成所有排列 — O(n × n!)
# 第一層 n 選擇 → 第二層 n-1 → ... → n! 個葉子
# 每個排列複製 O(n) → Total Time: O(n × n!)，Space: O(n) 遞迴深度
```

---

## 第四章：每個算法的複雜度速查表

### 4.1 搜尋與排序

```
┌──────────────────┬────────────┬────────────┬────────────┬──────────┐
│ 算法              │ Time Best  │ Time Avg   │ Time Worst │  Space   │
├──────────────────┼────────────┼────────────┼────────────┼──────────┤
│ Linear Search    │ O(1)       │ O(n)       │ O(n)       │ O(1)     │
│ Binary Search    │ O(1)       │ O(log n)   │ O(log n)   │ O(1)     │
│ Bubble Sort      │ O(n)       │ O(n²)      │ O(n²)      │ O(1)     │
│ Selection Sort   │ O(n²)      │ O(n²)      │ O(n²)      │ O(1)     │
│ Insertion Sort   │ O(n)       │ O(n²)      │ O(n²)      │ O(1)     │
│ Merge Sort       │ O(n log n) │ O(n log n) │ O(n log n) │ O(n)     │
│ Quick Sort       │ O(n log n) │ O(n log n) │ O(n²)      │ O(log n) │
│ Heap Sort        │ O(n log n) │ O(n log n) │ O(n log n) │ O(1)     │
│ Counting Sort    │ O(n + k)   │ O(n + k)   │ O(n + k)   │ O(k)    │
│ Radix Sort       │ O(nk)      │ O(nk)      │ O(nk)      │ O(n+k)  │
│ Bucket Sort      │ O(n + k)   │ O(n + k)   │ O(n²)      │ O(n)    │
│ Tim Sort (Python)│ O(n)       │ O(n log n) │ O(n log n) │ O(n)     │
└──────────────────┴────────────┴────────────┴────────────┴──────────┘
k = 值域範圍（Counting/Radix）或 bucket 數量
```

### 4.2 資料結構操作

```
┌──────────────────┬────────────────┬────────────────┬──────────┐
│ 資料結構 / 操作   │ Time Average   │ Time Worst     │  Space   │
├──────────────────┼────────────────┼────────────────┼──────────┤
│ Array access     │ O(1)           │ O(1)           │ O(n)     │
│ Array search     │ O(n)           │ O(n)           │ —        │
│ Array insert     │ O(n)           │ O(n)           │ —        │
│ Array append     │ O(1)*          │ O(n)*          │ —        │
│ Linked List head │ O(1)           │ O(1)           │ O(n)     │
│ Linked List srch │ O(n)           │ O(n)           │ —        │
│ HashMap get/set  │ O(1)           │ O(n)           │ O(n)     │
│ HashSet add/in   │ O(1)           │ O(n)           │ O(n)     │
│ Heap push        │ O(log n)       │ O(log n)       │ O(n)     │
│ Heap pop         │ O(log n)       │ O(log n)       │ —        │
│ Heap peek        │ O(1)           │ O(1)           │ —        │
│ Heapify (build)  │ O(n)           │ O(n)           │ O(1)     │
│ BST search       │ O(log n)       │ O(n)           │ O(n)     │
│ BST insert       │ O(log n)       │ O(n)           │ —        │
│ Trie insert      │ O(m)           │ O(m)           │ O(m×26)  │
│ Trie search      │ O(m)           │ O(m)           │ —        │
│ Union-Find       │ O(α(n)) ≈ O(1)│ O(α(n)) ≈ O(1)│ O(n)     │
│ Segment Tree qry │ O(log n)       │ O(log n)       │ O(n)     │
│ Segment Tree upd │ O(log n)       │ O(log n)       │ —        │
└──────────────────┴────────────────┴────────────────┴──────────┘
* Array append 是 amortized O(1)，偶爾需要擴容 O(n)
m = 字串長度，α = inverse Ackermann function（極度緩慢增長）
```

### 4.3 算法模式

```
┌────────────────────────┬──────────────┬──────────┬─────────────────────┐
│ 算法模式                │ Time         │ Space    │ 典型題目             │
├────────────────────────┼──────────────┼──────────┼─────────────────────┤
│ Two Pointers           │ O(n)         │ O(1)     │ Two Sum II, 3Sum    │
│ Sliding Window         │ O(n)         │ O(k)     │ Max Subarray, Anagram│
│ Binary Search          │ O(log n)     │ O(1)     │ Search Rotated Array│
│ Monotonic Stack        │ O(n)         │ O(n)     │ Next Greater Element│
│ BFS (Tree)             │ O(n)         │ O(w)     │ Level Order Traversal│
│ DFS (Tree)             │ O(n)         │ O(h)     │ Max Depth, Path Sum │
│ BFS/DFS (Graph)        │ O(V+E)       │ O(V)     │ Number of Islands   │
│ Topological Sort       │ O(V+E)       │ O(V)     │ Course Schedule     │
│ Dijkstra               │ O((V+E)logV) │ O(V)     │ Network Delay Time  │
│ Bellman-Ford           │ O(V×E)       │ O(V)     │ Cheapest Flights    │
│ Floyd-Warshall         │ O(V³)        │ O(V²)    │ All Pairs Shortest  │
│ DP (1D)                │ O(n)         │ O(n)/O(1)│ Climbing Stairs     │
│ DP (2D)                │ O(n×m)       │O(n×m)/O(n)│ Longest Common Subseq│
│ Backtracking (subsets) │ O(n × 2^n)   │ O(n)     │ Subsets             │
│ Backtracking (perms)   │ O(n × n!)    │ O(n)     │ Permutations        │
│ Backtracking (pruned)  │ varies       │ O(n)     │ N-Queens, Sudoku    │
│ Divide & Conquer       │ O(n log n)   │ O(n)     │ Merge Sort          │
│ Prefix Sum             │ O(n) build   │ O(n)     │ Range Sum Query     │
│ Bit Manipulation       │ O(n)         │ O(1)     │ Single Number       │
│ Union-Find             │ O(n × α(n))  │ O(n)     │ Connected Components│
│ Trie                   │ O(n × m)     │ O(n×m×26)│ Word Search II      │
└────────────────────────┴──────────────┴──────────┴─────────────────────┘
w = 樹的最大寬度，h = 樹的高度
```

---

## 第五章：空間複雜度分析

### 5.1 什麼算空間複雜度？

空間複雜度衡量的是**額外使用的記憶體**，不包含輸入本身。

```python
def find_max(arr):       # O(1) 空間 — 只用 result 和 x
    result = arr[0]
    for x in arr:
        result = max(result, x)
    return result

def double_array(arr):   # O(n) 空間 — 新陣列大小 = n
    return [x * 2 for x in arr]

def count_freq(arr):     # O(n) 空間 — HashMap 最多 n 個 key
    freq = {}
    for x in arr:
        freq[x] = freq.get(x, 0) + 1
    return freq
```

### 5.2 遞迴的隱藏空間 — Call Stack

**很多人會忘記 call stack 也佔空間！**

```python
# 範例：計算陣列總和（遞迴版）
def sum_recursive(arr, i=0):
    if i == len(arr):
        return 0
    return arr[i] + sum_recursive(arr, i + 1)

# Call stack（n=5）：
# sum_recursive(arr, 0)  ← 還沒 return，佔一層
#   sum_recursive(arr, 1)
#     sum_recursive(arr, 2)
#       sum_recursive(arr, 3)
#         sum_recursive(arr, 4)
#           sum_recursive(arr, 5) → return 0
# 最深 6 層 → 空間 O(n)
```

各種遞迴的空間複雜度：

```
┌─────────────────────┬────────────────┬──────────────────────────┐
│ 遞迴類型             │ Call Stack 深度│  說明                     │
├─────────────────────┼────────────────┼──────────────────────────┤
│ Linear recursion    │ O(n)           │ f(n) → f(n-1) → f(n-2)  │
│ Binary Search (rec) │ O(log n)       │ 每次砍半                  │
│ Balanced Tree DFS   │ O(log n)       │ 高度 = log n             │
│ Skewed Tree DFS     │ O(n)           │ 高度 = n（退化成鏈表）    │
│ General Tree DFS    │ O(h)           │ h = 樹的高度             │
│ Graph DFS           │ O(V)           │ 最壞全部連成一線          │
│ Merge Sort          │ O(log n) stack │ 但額外需要 O(n) 合併空間  │
│ Quick Sort          │ O(log n) avg   │ 最壞 O(n) 若 pivot 極差  │
│ Backtracking        │ O(n)           │ 遞迴深度 = 決策層數       │
│ Fibonacci (naive)   │ O(n)           │ 樹的最左路徑深度 = n      │
└─────────────────────┴────────────────┴──────────────────────────┘
```

### 5.3 In-place 算法 — O(1) 額外空間

```python
# Two Pointers — O(1) 空間
def reverse_array(arr):
    left, right = 0, len(arr) - 1
    while left < right:
        arr[left], arr[right] = arr[right], arr[left]
        left += 1
        right -= 1
# 只用了 left, right 兩個指標 → O(1)

# Quick Sort (in-place partition) — O(log n) 空間
# 不需要額外陣列（不像 Merge Sort），但 call stack 佔 O(log n)

# Floyd's Cycle Detection — O(1) 空間
def has_cycle(head):
    slow = fast = head
    while fast and fast.next:
        slow = slow.next
        fast = fast.next.next
        if slow == fast:
            return True
    return False
# 只用了 slow, fast 兩個指標 → O(1)
```

### 5.4 空間優化技巧

```python
# DP 空間優化：從 O(n) 到 O(1)
# Fibonacci 原始版：dp = [0]*(n+1)，用 O(n)
# 優化版：只保留 prev2, prev1 → O(1)
def fib_optimized(n):
    if n <= 1: return n
    prev2, prev1 = 0, 1
    for i in range(2, n + 1):
        prev2, prev1 = prev1, prev1 + prev2
    return prev1

# 2D DP 空間優化：從 O(n×m) 到 O(min(n,m))

# Longest Common Subsequence — 原始版 O(n×m)
def lcs(text1, text2):
    n, m = len(text1), len(text2)
    dp = [[0] * (m + 1) for _ in range(n + 1)]  # O(n×m)
    for i in range(1, n + 1):
        for j in range(1, m + 1):
            if text1[i-1] == text2[j-1]:
                dp[i][j] = dp[i-1][j-1] + 1
            else:
                dp[i][j] = max(dp[i-1][j], dp[i][j-1])
    return dp[n][m]

# LCS — 優化版 O(m)：只保留上一行 prev 和當前行 curr
# 因為 dp[i][j] 只依賴 dp[i-1][j], dp[i][j-1], dp[i-1][j-1]
# → 空間從 O(n×m) 降到 O(m)
```

---

## 第六章：Amortized 攤銷分析

### 6.1 什麼是 Amortized Analysis？

有些操作**偶爾很貴，大部分時候很便宜**。Amortized Analysis 把貴的操作「攤」到便宜的操作上，算出平均每次操作的成本。

**生活比喻**：你每天花 10 元買午餐，但每 30 天要花 300 元買一雙新鞋。平均每天花 10 + 300/30 = 20 元。不能說你「有一天花了 300 元，所以日常開銷是 300 元」。

### 6.2 Dynamic Array（Python list.append）

```python
# Python 的 list.append() 是 O(1) amortized
# 容量滿了就擴容翻倍，擴容時複製所有元素 → O(n)

# 假設初始容量 = 1，每次擴容翻倍：
# append #1:  容量 1→2,  複製 1 個   ← 貴
# append #2:  容量 2→4,  複製 2 個   ← 貴
# append #3:  直接放入               ← 便宜
# append #4:  容量 4→8,  複製 4 個   ← 貴
# append #5~7: 直接放入              ← 便宜
# append #8:  容量 8→16, 複製 8 個   ← 貴

# n 次 append 的總複製次數 = 1+2+4+...+n = 2n-1（等比級數）
# 總成本 ≈ 3n → 平均每次 = O(1) amortized
```

### 6.3 為什麼 Sliding Window 是 O(n) 而不是 O(n²)？

```python
# 看起來像 O(n²) 的 Sliding Window：
def max_sliding_window_deque(nums, k):
    from collections import deque
    dq = deque()  # 存 index
    result = []
    for i in range(len(nums)):           # 外層 n 次
        while dq and nums[dq[-1]] <= nums[i]:
            dq.pop()                      # 這個 while 不是 O(n)！
        dq.append(i)
        if dq[0] <= i - k:
            dq.popleft()
        if i >= k - 1:
            result.append(nums[dq[0]])
    return result

# 為什麼是 O(n)？
#
# 關鍵觀察：每個元素最多被 push 一次、pop 一次
#
# 追蹤 nums = [1, 3, -1, -3, 5, 3], k = 3：
#
# i=0: push(0)                       dq=[0]           → push 1次
# i=1: pop(0), push(1)               dq=[1]           → pop 1次, push 1次
# i=2: push(2)                       dq=[1,2]         → push 1次
# i=3: push(3)                       dq=[1,2,3]       → push 1次
#      popleft(1) (出窗口)            dq=[2,3]         → popleft 1次
# i=4: pop(3), pop(2), push(4)       dq=[4]           → pop 2次, push 1次
# i=5: push(5)                       dq=[4,5]         → push 1次
#
# 統計：push 共 6 次，pop 共 3 次，popleft 共 1 次
# 每個元素 push 1 次 + pop 最多 1 次 = 最多 2n 次操作
# Total: O(2n) = O(n)
```

### 6.4 為什麼 Monotonic Stack 是 O(n)？

```python
# Next Greater Element — 看起來像 O(n²)
def next_greater(nums):
    n = len(nums)
    result = [-1] * n
    stack = []
    for i in range(n):              # 外層 n 次
        while stack and nums[stack[-1]] < nums[i]:
            idx = stack.pop()       # 這個 while 不是 O(n)！
            result[idx] = nums[i]
        stack.append(i)
    return result

# 追蹤 nums = [2, 1, 2, 4, 3]：
#
# i=0: push(0)                  stack=[0]        → push
# i=1: push(1)                  stack=[0,1]      → push
# i=2: pop(1), push(2)          stack=[0,2]      → pop, push
# i=3: pop(2), pop(0), push(3)  stack=[3]        → pop, pop, push
# i=4: push(4)                  stack=[3,4]      → push
#
# push 共 5 次（每個元素恰好 push 一次）
# pop  共 3 次（每個元素最多 pop 一次）
# Total ≤ 2n = O(n)

# 核心論證：
# 每個元素最多 push 一次 → 總 push 次數 ≤ n
# 每個元素最多 pop 一次  → 總 pop 次數 ≤ n
# 所以 while 迴圈的總執行次數 ≤ n（攤到所有外層迭代）
# Total: O(n) + O(n) = O(n)
```

### 6.5 為什麼 Two Pointers 是 O(n)？

```python
# 看起來有兩個指標在動，但 Total 是 O(n)
def remove_duplicates(nums):
    if not nums:
        return 0
    slow = 0
    for fast in range(1, len(nums)):  # fast 從 1 走到 n-1
        if nums[fast] != nums[slow]:
            slow += 1
            nums[slow] = nums[fast]
    return slow + 1

# fast 走了 n-1 步，slow 最多走 n-1 步
# 但 fast 和 slow 是各自獨立的、只往前走
# Total: O(n)

# 兩端逼近的 Two Pointers
def two_sum_sorted(nums, target):
    left, right = 0, len(nums) - 1
    while left < right:
        s = nums[left] + nums[right]
        if s == target:
            return [left, right]
        elif s < target:
            left += 1
        else:
            right -= 1

# left 只往右走，right 只往左走
# 兩者加起來最多走 n 步 → O(n)
```

---

## 第七章：面試中如何回答複雜度問題

### 7.1 回答模板

面試官問 "What's the time and space complexity?" 時，用這個結構：

```
模板：
"The time complexity is O(___) because [原因].
 The space complexity is O(___) because [原因]."

範例 1（Binary Search）：
"The time complexity is O(log n) because we halve the search
 space in each iteration, so we need at most log₂(n) iterations.
 The space complexity is O(1) because we only use a constant
 number of variables (left, right, mid)."

範例 2（BFS on Graph）：
"The time complexity is O(V + E) because we visit each vertex
 at most once, which is O(V), and for each vertex we examine
 all its edges, which totals O(E) across all vertices.
 The space complexity is O(V) because we store a visited set
 of size V and the queue can hold at most V nodes."

範例 3（Merge Sort）：
"The time complexity is O(n log n) because we divide the array
 into two halves at each level, creating log n levels, and at
 each level we do O(n) work to merge.
 The space complexity is O(n) because the merge step requires
 a temporary array of size n, plus O(log n) for the recursion
 call stack."
```

### 7.2 常見錯誤

```
❌ 錯誤 1：忘記 HashMap 的 worst case
"HashMap lookup is O(1)."
→ 更精確："HashMap lookup is O(1) on average. In the worst case,
   with many hash collisions, it degrades to O(n)."
   (面試中通常可以假設 O(1)，但要知道 worst case。)

❌ 錯誤 2：忽略字串操作的成本
s += char  # 在 Python 中是 O(len(s))，不是 O(1)！
→ 字串是 immutable（不可變），每次 += 都會建立新字串
→ 如果在迴圈中做 n 次：O(1+2+...+n) = O(n²)
→ 正確做法：用 list 收集再 "".join(list)

❌ 錯誤 3：忘記遞迴的 call stack 空間
"Tree DFS 的空間複雜度是 O(1)，因為沒有用額外陣列。"
→ 錯！call stack 也是空間。Tree DFS 空間 = O(h)，h = 高度。

❌ 錯誤 4：把 O(n + m) 說成 O(n)
"遍歷兩個陣列 A (長度 n) 和 B (長度 m) 是 O(n)。"
→ 應該是 O(n + m)。除非題目說 n = m，否則不能忽略 m。

❌ 錯誤 5：Sorting 之後忘了算 sort 的成本
def find_median(arr):
    arr.sort()           # O(n log n) ← 不能忽略！
    return arr[len(arr)//2]
# Total: O(n log n)，不是 O(1)

❌ 錯誤 6：搞混 Tree 和 Graph 的複雜度
- Tree: V = n, E = n-1, 所以 O(V+E) = O(n)
- Graph: E 可以到 V²（完全圖），O(V+E) ≠ O(V)

❌ 錯誤 7：把 heap 的 heapify 說成 O(n log n)
heapq.heapify(arr)  # 是 O(n)，不是 O(n log n)！
# 逐個 push 是 O(n log n)，但 Floyd's sift-down heapify 是 O(n)
```

### 7.3 面試官追問 "Can you do better?" 時的思路

```
當前複雜度 → 常見的優化方向：

O(n²) → O(n log n)：
  「可以考慮 sorting + two pointers，或用 heap。」

O(n²) → O(n)：
  「可以用 HashMap 把內層查找從 O(n) 降到 O(1)。」
  「可以用 Sliding Window 避免重複計算。」
  「可以用 Monotonic Stack 預處理。」

O(n log n) → O(n)：
  「如果不需要排序，可以用 HashMap / Counting Sort。」
  「Quickselect 可以在 O(n) 找第 k 大。」

O(2^n) → O(n × 2^n) 或 O(n²)：
  「有沒有重疊子問題？如果有，DP 可以大幅降低。」
  「Fibonacci: O(2^n) → O(n) with DP。」

O(n) → O(log n)：
  「如果資料已排序，Binary Search 可以做到 O(log n)。」

O(n) → O(1)：
  「有沒有數學公式？例如等差數列求和 = n(n+1)/2。」
```

### 7.4 完整面試演練（Two Sum）

```
你：「Brute force 兩層迴圈 → Time O(n²), Space O(1)」
面試官：「Can you do better?」
你：「用 HashMap，遍歷一次。Time O(n) — iterate once, each lookup O(1).
     Space O(n) — worst case store all n elements.」
面試官：「What if the array is sorted?」
你：「Two Pointers, left 和 right 往中間逼近。
     Time O(n) — each pointer moves at most n steps.
     Space O(1) — only two variables. 但要先 sort 的話是 O(n log n).」
```

---

## 第八章：進階複雜度分析

### 8.1 多變數複雜度

有些問題的複雜度不只取決於一個變數：

```
O(V + E)  — BFS/DFS on Graph（V = 節點數, E = 邊數，兩者獨立）
O(n + m)  — KMP 字串匹配（n = text 長度, m = pattern 長度）
O(n × m)  — 2D DP（n = 第一維, m = 第二維）
O(n × m)  — Trie 建樹（n = 單詞數, m = 平均單詞長度）

面試表達：
"The time complexity is O(V + E), where V is the number of
 vertices and E is the number of edges."
```

### 8.2 Best / Average / Worst Case 的區別

```
Quick Sort 的三種情況：

Best Case:  O(n log n) → pivot 選到中位數，均勻分割
Avg Case:   O(n log n) → 隨機 pivot，期望均勻
Worst Case: O(n²)      → pivot 選到最小/最大值，每次只分出 1 個

數值範例（n = 10000）：
Best ≈ 130,000 次比較 vs Worst = 50,005,000 次比較 → 差 385 倍

HashMap — Best/Avg: O(1) lookup，Worst: O(n)（hash collision）
```

### 8.3 遞迴 + Memoization 的通用公式

```
Time = (狀態數) × (每個狀態的計算成本)

Coin Change:  狀態 = amount, 每狀態遍歷 c 個 coin → O(amount × c)
LIS (DP):     狀態 = n, 每狀態遍歷 n 個前驅       → O(n²)
Bitmask DP:   狀態 = 2^n, 每狀態轉移 O(n)          → O(n × 2^n)
```

---

## 總結：複雜度分析 Cheat Sheet

### 快速判斷法

```
看到什麼 → 想到什麼複雜度：

看到 HashMap/HashSet 查找        → O(1) average
看到 for 迴圈跑一遍              → O(n)
看到 for 裡面套 for              → O(n²)
看到每次砍半（/2 或 mid）        → O(log n)
看到 sort                        → O(n log n)
看到 BFS/DFS on tree             → O(n)
看到 BFS/DFS on graph            → O(V + E)
看到 Backtracking + subsets      → O(2^n)
看到 Backtracking + permutations → O(n!)
看到 DP 填表 n×m                 → O(n × m)
看到 Heap push/pop               → O(log n)
看到 Heapify                     → O(n)
看到 Union-Find with rank+path   → O(α(n)) ≈ O(1) amortized
看到 Trie 操作                   → O(word length)
看到 Sliding Window              → O(n) amortized
看到 Monotonic Stack             → O(n) amortized
看到 Prefix Sum 建構             → O(n) 建構，O(1) 查詢
看到 Segment Tree 操作           → O(log n) per query/update
```

### 完整複雜度排名（從快到慢）

```
O(1) < O(log n) < O(√n) < O(n) < O(n log n) < O(n²) < O(n³) < O(2^n) < O(n!)

具體數值（n = 1,000,000）：
O(1)        = 1
O(log n)    = 20
O(√n)       = 1,000
O(n)        = 1,000,000
O(n log n)  = 20,000,000
O(n²)       = 1,000,000,000,000         ← 已經跑不動了
O(n³)       = 10^18                       ← 宇宙等級
O(2^n)      = 10^301,030                  ← 遠超宇宙原子數
O(n!)       = ... （根本寫不出來）
```

### 面試回答的黃金三步驟

```
Step 1：說出複雜度
"The time complexity is O(n log n)."

Step 2：解釋原因
"Because we sort the array first in O(n log n), then do a
 linear scan in O(n). The dominant term is O(n log n)."

Step 3：說出空間
"The space complexity is O(1) extra space, since we sort
 in-place and only use constant variables."

完整範例：
"For this solution, the time complexity is O(n) because we use
 a sliding window that processes each element at most twice —
 once when expanding the right boundary and once when shrinking
 the left boundary. The space complexity is O(k) where k is the
 size of the character set, because we maintain a HashMap to
 track character frequencies within the window."
```

---

> **記住**：複雜度分析不是背公式，而是**理解算法對每個元素做了什麼**。
> 問自己：「每個元素被處理了幾次？」— 這個問題的答案就是你的 Time Complexity。
