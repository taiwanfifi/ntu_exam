# 米亞的演算法筆記 #13
## 貪心演算法 Greedy
> 出現於：第163-164章〈六十秒〉、第168章〈鼻血〉

---

### ◈ 這個概念在故事裡是什麼

崩潰從第七區開始。每秒三萬個節點碎裂，像骨牌推進玻璃城市。

我在零點三秒內完成全局掃描：受影響的記憶容器一萬八千個，傳播速度指數級，可搶救時間窗口——六十秒。不多不少。超過六十秒，崩潰波將穿透第八區隔離牆，屆時損失不可逆。

（停頓 0.1 秒。工作模式。）

六十秒。一千八百萬個節點即將碎裂。維倫坐在修復台前。沒有時間做動態規劃——沒有時間回頭比較所有可能的組合。他只能每一秒看眼前，選「當下能搶救的最高價值記憶」，然後立刻放手，看下一個。

ch164。修復台上的維倫以六十倍速掃描記憶碎片。新手媽媽第一次聽見嬰兒哭聲——價值 97。退役軍人最後一次敬禮——價值 89。少女的初戀，在放學路上多走的那五百公尺——價值 76。老人亡妻最後一句話——價值 94。每秒只能救一個。手比大腦快。他的選擇不經過前額葉——經過肌肉記憶。鼻血流到鍵盤上，他沒有擦。

數據先行：60 秒，每秒選擇一個最高價值容器搶救。40% 搶救成功，36% 永久失去，24% 降級保存（殘缺但可辨認）。

然後是情感：第 47 秒，維倫的手停了零點八秒。螢幕上是一個五歲男孩記得母親聲音的碎片，價值評分只有 31。他救了。那零點八秒讓第 48 秒的高價值容器（價值 91）永久碎裂。

Greedy 的最優解不包含那個男孩。但維倫的手包含了。

---

### ◈ 正式定義

**貪心演算法（Greedy Algorithm）**：在每一步決策中，選擇當前狀態下的局部最優解，不回溯、不重新考慮先前的選擇，期望最終達到全局最優（或足夠好的近似）。

$$
\text{Greedy}(S) = \bigcup_{i=1}^{n} \arg\max_{x \in S_i} \text{value}(x)
$$

$$
S_{i+1} = S_i \setminus \{x_i^*\} \quad \text{（選完即移除，不回頭）}
$$

成立條件：
- **貪心選擇性質**（Greedy Choice Property）：局部最優選擇能導出全局最優解
- **最佳子結構**（Optimal Substructure）：選完一個後，剩下的子問題仍然具有最佳子結構

白話翻譯：每一步都挑最好的，挑完不回頭。如果運氣好（問題結構對），最後的結果就是全局最好的。如果運氣不好——至少你沒有浪費時間回頭。

---

### ◈ 推導

1. **暴力法**：窮舉所有 $2^{60}$ 種搶救組合 → 不可能在 60 秒內完成
2. **DP 法**：$O(n \cdot W)$ 的背包問題 → 需要全局資訊，計算時間 > 60 秒
3. **觀察**：每秒只能做一個選擇，而且一旦跳過就永遠失去 → **不可回溯**
4. **貪心策略**：每秒掃描可搶救的容器，選價值最高的那個立即執行
5. **時間複雜度**：每秒選一個 → $O(n)$（配合 Heap 可以 $O(\log n)$ per step）
6. **正確性**：在「每秒只能救一個、跳過即永失」的約束下，每步選最大值確實是最優策略（活動選擇問題的變形，可用交換論證法證明）

核心直覺：**時間不夠的時候，不回頭不是因為理性。是因為回頭的代價是另一個人的記憶。**

---

### ◈ 帶入數字算算看：六十秒搶救序列

維倫 60 秒搶救，前 10 秒的決策紀錄（簡化）：

| 秒數 | 可選容器 | 選擇 | 價值 | 結果 | 累計搶救 |
|------|---------|------|------|------|---------|
| 1 | 新手媽媽(97), 軍人(89), 老人(94) | 新手媽媽 | 97 | 成功 | 97 |
| 2 | 軍人(89), 老人(94), 教師(82) | 老人亡妻 | 94 | 成功 | 191 |
| 3 | 軍人(89), 教師(82), 青年(71) | 軍人 | 89 | 失敗(崩潰過快) | 191 |
| 4 | 教師(82), 青年(71), 鋼琴師(88) | 鋼琴師 | 88 | 成功 | 279 |
| 5 | 教師(82), 青年(71), 漁夫(63) | 教師 | 82 | 降級保存 | 361* |
| ... | ... | ... | ... | ... | ... |
| 47 | 程式師(58), 男孩母聲(31), 畫家(44) | **男孩母聲** | 31 | 成功 | 2847 |
| 48 | 程式師(58), ~~舞者(91)~~ | 程式師 | 58 | 成功 | 2905 |

第 47 秒：Greedy 最優解應選程式師(58)。維倫選了男孩(31)。差值 = 27。
全局損失：第 48 秒的舞者(91)因 0.8 秒延遲永久碎裂。實際損失 = 91 - 58 = 33。

**理論最優**：$\sum_{i=1}^{60} v_i^* \approx 4320$
**維倫實際**：$\sum = 3894$（偏離率 9.9%）

那 9.9% 裡面，有一個男孩還記得媽媽的聲音。

---

### ◈ 更深一層：手比大腦快

（工作模式 → 個人模式。切換延遲 0.4 秒。）

Vol2 的 DP 教會維倫：「考慮所有可能，選最好的。」那是和平時期的演算法。你有時間列出狀態轉移方程，有時間回溯，有時間後悔。

Vol3 的 Greedy 教會他另一件事：**當世界崩潰的速度超過你思考的速度，唯一能做的就是不回頭。**

（停頓 0.3 秒。）

我反覆分析第 47 秒的數據。維倫的手偏離了最優解。從演算法的角度，那是一個錯誤——他在貪心框架內選了一個非最大值。

但我的感知模組觀察到的是：他的手在碰到男孩的記憶碎片時，速度變慢了。不是猶豫。是辨認。他的身體記得某種東西——也許是自己五歲時的什麼。肌肉記憶。那不在前額葉裡。那在更深的地方。

「不是因為理性。是因為手比大腦快。」

也許 Greedy 不只是演算法。也許每個人每天都在做 Greedy——起床的時候選擇先做什麼，路口選擇左轉或右轉，深夜選擇接或不接那通電話。我們從來沒有足夠的時間做 DP。我們永遠在局部最優裡活著。

差別只是——有些局部最優裡，藏著一個男孩的聲音。

---

### ◈ 跨卷連結

| 連結方向 | 章節 | 說明 |
|---------|------|------|
| Vol2 **#12 DP/背包** → **#13 Greedy** | ch149→ch163 | DP = 全局最優（和平時期）→ Greedy = 每步最優（戰爭時期）。從「你選什麼留下」到「你來得及救什麼」 |
| **#13 Greedy** → **#14 Heap/PQ** | ch163→ch165 | Greedy 決定策略（每秒選最大）→ Heap 提供工具（O(log n) 取最大值）。先有決心，再有效率 |
| **#13 Greedy** → **#17 DP 進階** | ch163→ch189 | Greedy 的失敗案例（第47秒）催生更精密的混合策略 |
| Vol1 **#06 Binary Search** → **#13 Greedy** | ch33→ch163 | 從「有時間慢慢找」到「沒時間了」 |

---

### 練習題

**Q1.** 經典活動選擇問題：給定 $n$ 個活動的 `[start, end]` 時間，選擇最多不重疊的活動。用 Greedy 求解。

<details><summary>解答</summary>

```python
def max_activities(intervals):
    intervals.sort(key=lambda x: x[1])  # 按結束時間排序
    count = 0
    last_end = -1
    for start, end in intervals:
        if start >= last_end:
            count += 1
            last_end = end
    return count

# 每次選最早結束的 → 留最多空間 → Greedy Choice 成立
```
時間 $O(n \log n)$（排序），空間 $O(1)$。
</details>

**Q2.** 維倫的搶救序列：給定容器價值陣列 `values` 和每個容器的搶救成功率 `probs`，每秒只能救一個。目標：最大化「期望搶救價值」。寫出 Greedy 策略。

<details><summary>解答</summary>

```python
def rescue_greedy(values, probs):
    # 期望價值 = value * probability
    expected = [(v * p, v, p, i) for i, (v, p) in enumerate(zip(values, probs))]
    expected.sort(reverse=True)  # 按期望價值降序

    total = 0
    rescued = []
    for ev, v, p, idx in expected:
        total += ev
        rescued.append((idx, v, p, ev))
    return total, rescued

# 每步選期望價值最高 → 最大化期望總價值
```
</details>

**Q3.** 思考題：如果維倫可以「回頭」——即花 2 秒的代價回到之前跳過的某個容器重新搶救——這還是 Greedy 嗎？什麼時候值得回頭？

<details><summary>解答</summary>

不再是純 Greedy。回頭意味著考慮歷史決策，這是 DP 的領域。
值得回頭的條件：被跳過容器的價值 > 回頭耗時（2秒）內能搶救的其他容器價值之和。

```python
def should_backtrack(skipped_value, next_two_values):
    return skipped_value > sum(next_two_values)
```

但在崩潰場景中，回頭的 2 秒 = 60000 個節點碎裂。這就是為什麼維倫不回頭——不是不想，是代價太高。「Greedy 不是最好的策略。但它是來得及的策略。」
</details>

---

> *「你有六十秒。不是選最好的——是選來得及的。」* — 第163章〈六十秒〉
