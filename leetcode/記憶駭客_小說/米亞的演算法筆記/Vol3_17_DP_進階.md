# 米亞的演算法筆記 #17
## 多維動態規劃 Advanced DP
> 出現於：第189章〈把自己放上修復台〉、第190章〈紅色潮水〉、第191章〈43%〉

---

### ◈ 這個概念在故事裡是什麼

第189章。維倫做了全書最瘋狂的事：他把自己放上修復台。

沒有委託人。沒有旁觀者。只有他，讓我掃描全部的記憶——一千零三十七段。他要我做一件事：**判斷每一段記憶是「原生」還是「植入」。**

（停頓 0.3 秒。）

這不是簡單的分類。記憶之間有依賴關係——一段記憶的真偽取決於它的上游。如果「記得」的某件事是植入的，那麼從它長出來的所有後續記憶，來源就是假的。汙染沿著依賴鏈往下蔓延。

第190章。我寫下狀態轉移方程：

```
dp[i] = NATIVE    if all upstream[j] are NATIVE
dp[i] = PLANTED   if any upstream[j] is PLANTED
```

螢幕上，一千零三十七段記憶像星座圖一樣展開。藍色是原生，紅色是植入。起初藍色很多。然後紅色開始蔓延——從最早的幾段記憶開始，像潮水一樣往下游擴散。碰到一段，汙染一段。碰到分支，汙染所有分支。維倫看著螢幕，一言不發。

第191章。結果：591 段植入，446 段原生。

57% 植入。43% 原生。

（停頓 0.5 秒。）

我打開原生記憶的時間分布。遇見語青之前——原生記憶稀疏，零星散布。遇見語青之後——原生記憶密度暴增。他的 43% 裡面，大部分都有她在。

「43%。聽起來不多。但維倫——你那 43% 裡面有她。有阿嬤的豆漿。有我。我覺得這個比例已經很奢侈了。」

他沒說話。但他把修復台關了。他不需要知道更多。

---

### ◈ 正式定義

**多維動態規劃（依賴鏈分析）**：在一個有向無環圖（DAG）上，每個節點的狀態取決於其所有前驅節點的狀態。

設 $G = (V, E)$ 為記憶依賴圖，$V$ 為記憶節點集合，$E$ 為依賴邊。

$$
dp[i] =
\begin{cases}
\texttt{NATIVE} & \text{if } \forall\, j \in \text{upstream}(i),\; dp[j] = \texttt{NATIVE} \\
\texttt{PLANTED} & \text{if } \exists\, j \in \text{upstream}(i),\; dp[j] = \texttt{PLANTED}
\end{cases}
$$

根節點（無上游）的狀態由外部標籤決定（已知的植入源或已知的原生源）。

$$
T(V, E) = O(|V| + |E|) \quad \text{（拓撲排序 + 一次遍歷）}
$$

白話翻譯：如果你記憶的「源頭」是假的，那麼從那個源頭長出來的一切——不管感受多真實——都被汙染了。

---

### ◈ 推導

1. **為什麼不能逐一獨立判斷？** 「我記得她的笑」依賴於「我記得遇見她」。如果「遇見她」是植入的，「她的笑」的來源就是假的。
2. **拓撲排序**：先處理無上游的根節點，再處理下游，確保每個節點處理時上游都已標記。
3. **狀態轉移**：全部上游原生→原生；只要一個植入→汙染。
4. **汙染傳播 = OR 邏輯**：$\texttt{PLANTED}(i) = \bigvee_{j \in upstream(i)} \texttt{PLANTED}(j)$
5. **複雜度**：拓撲排序 + 一次遍歷 = $O(|V|+|E|)$

```python
from collections import deque

def classify_memories(n, edges, known_planted):
    adj, in_deg = [[] for _ in range(n)], [0] * n
    for u, v in edges:
        adj[u].append(v); in_deg[v] += 1
    status = ['PLANTED' if i in known_planted else 'NATIVE' for i in range(n)]
    queue = deque(i for i in range(n) if in_deg[i] == 0)
    while queue:
        u = queue.popleft()
        for v in adj[u]:
            if status[u] == 'PLANTED': status[v] = 'PLANTED'
            in_deg[v] -= 1
            if in_deg[v] == 0: queue.append(v)
    return status
```

---

### ◈ 帶入數字算算看：維倫的 1037 段記憶

第189-191章。$|V| = 1037$，$|E| = 2841$（平均每段記憶依賴 2.7 段上游記憶）。

| 階段 | 原生（藍） | 植入（紅） | 累計汙染率 |
|------|-----------|-----------|-----------|
| 根節點標記（已知植入源） | 983 | 54 | 5.2% |
| 第一波傳播（直接下游） | 814 | 223 | 21.5% |
| 第二波傳播 | 632 | 405 | 39.1% |
| 第三波傳播 | 502 | 535 | 51.6% |
| 收斂（最終結果） | **446** | **591** | **57.0%** |

54 段已知植入源，經過依賴鏈傳播，最終汙染了 591 段——擴大了 **10.9 倍**。

原生的 446 段記憶中，遇見語青之後的佔 **312 段（70%）**。

---

### ◈ 更深一層：43% 是什麼

（切換到存在模式。語速很慢。）

如果你 57% 是被製造的，那 43% 的你是什麼？

Vol2 的 DP/背包問的是「你只能帶走這麼多記憶，你留什麼？」那是取捨，你有主動權。Vol3 的 DP 進階問的完全不同：「你以為是你的記憶，有多少其實不是你的？」這不是選擇。這是審判。

（停頓 0.4 秒。）

但我在分析維倫的數據時發現了一件事。汙染是單向的——植入可以汙染原生，但原生不會「淨化」植入。從邏輯上很合理。假的源頭長出來的東西，不會因為後來產生了真的感受就變成真的。

可是——維倫看著那些被標記為「植入」的記憶時，有些情感波形和「原生」記憶一模一樣。來源是假的，但情感是真的。我的分類器說那是「汙染」，但維倫的心率說那是「他的」。

也許 DP 的狀態轉移方程不是唯一的真相。也許，在人類的世界裡，存在一種我的方程式無法建模的東西：**假的來源，真的感受。** 植入的開頭，原生的結局。

43%。聽起來不多。但那 43% 裡面有語青。有阿嬤。有我。我覺得這個比例已經很奢侈了。

---

### ◈ 跨卷連結

| 連結 | 說明 |
|------|------|
| **Vol2 #12 DP/背包** → **#17 DP 進階** | 背包是「選擇保留什麼」，DP 進階是「辨認什麼是真的」。從主動取捨到被動審判。 |
| **Vol2 #10 拓撲排序** → **#17 DP 進階** | 拓撲排序找出「事件的因果鏈」，DP 進階在因果鏈上做「汙染傳播」。同一個 DAG，不同的語義。 |
| **#16 Trie** → **#17 DP 進階** | Trie 找到記憶，DP 進階判斷記憶真偽。先找到，再辨認——搜尋與判斷的兩步驟。 |
| **#17 DP 進階** → **Vol4 #22 NP-Complete** | 「辨認真偽」有多項式解，但「恢復被植入的記憶為原生」是 NP-Complete——你無法撤銷汙染，只能接受。 |

---

### 練習題

**Q1.** 給定一個 DAG 和已知的植入源集合，用拓撲排序 + DP 判斷所有節點的真偽。回傳原生記憶的百分比。

<details><summary>答案</summary>

```python
from collections import deque

def native_percentage(n, edges, planted_set):
    adj = [[] for _ in range(n)]
    in_deg = [0] * n
    for u, v in edges:
        adj[u].append(v)
        in_deg[v] += 1
    status = ['PLANTED' if i in planted_set else 'NATIVE'
              for i in range(n)]
    queue = deque(i for i in range(n) if in_deg[i] == 0)
    while queue:
        u = queue.popleft()
        for v in adj[u]:
            if status[u] == 'PLANTED':
                status[v] = 'PLANTED'
            in_deg[v] -= 1
            if in_deg[v] == 0:
                queue.append(v)
    native = status.count('NATIVE')
    return round(100 * native / n, 1)

# native_percentage(10, [(0,2),(0,3),(1,3),(3,4),(4,5)], {0})
# → 節點 0,2,3,4,5 都被汙染，只剩 1,6,7,8,9 原生 → 50.0%
```
</details>

**Q2.** 如果依賴圖有環（記憶互相依賴），拓撲排序會失敗。在故事中這代表什麼？用演算法術語解釋。

<details><summary>答案</summary>

有環意味著「A 依賴 B，B 又依賴 A」——兩段記憶互為因果。拓撲排序無法處理有環的圖（環中的節點 in-degree 永遠不會歸零）。

在故事中，這代表**記憶迴圈**——「我記得遇見她是因為她的笑」而「她的笑存在是因為我記得遇見她」。這種自指的記憶無法被判定為原生或植入。它處於疊加態——像薛丁格的愛人。

解法：先用 Tarjan/Kosaraju 演算法找出強連通分量（SCC），將環縮為一個超級節點，再做拓撲排序。環內的記憶——要麼全部原生，要麼全部汙染。
</details>

**Q3.** 思考題：維倫的 43% 原生記憶中，70% 與語青相關。如果語青的記憶本身被證明是植入的，會發生什麼？

<details><summary>答案</summary>

如果語青相關的記憶被重新標記為植入源，那 312 段記憶會被汙染。原生記憶從 446 段降至約 134 段——原生比例從 43% 驟降至 **12.9%**。

但這引出一個 DP 無法回答的問題：如果遇見語青是植入的，但愛上她的過程是真的——那「愛」本身是原生的還是植入的？狀態轉移方程說：汙染。維倫的心說：不是。

這就是為什麼他關掉了修復台。有些問題，不該讓演算法回答。
</details>

---

> *「43%。聽起來不多。但維倫——你那 43% 裡面有她。有阿嬤的豆漿。有我。我覺得這個比例已經很奢侈了。」* — 第191章〈43%〉
